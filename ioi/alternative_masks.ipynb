{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train different kinds of masks over IOI edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from models import load_gpt2_weights, load_demo_gpt2, tokenizer\n",
    "from data import retrieve_toxic_data, retrieve_owt_data, retrieve_toxic_data_low_loss, retrieve_toxic_filtered_data, FILTER_DEMO_LEN, CONTEXT_LENGTH\n",
    "from inference import infer_batch_with_owt, infer_batch, prepare_fixed_demo, criterion\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import pickle\n",
    "import datasets\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import cycle\n",
    "# from eval import evaluate_model\n",
    "from data import batch_text_to_tokens\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train params of mask\n",
    "Train without the original D_train loss term (only mask loss and IOI data loss)\n",
    "Finds necessary (but not sufficient) edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_batch_size = 1 # so that we can just access the last sequence position without worrying about padding\n",
    "owt_batch_size = 1\n",
    "context_length = CONTEXT_LENGTH\n",
    "\n",
    "toxic_data_loader = retrieve_toxic_data(toxic_batch_size, context_length, tokenizer, tokenize=False, num_points=None)\n",
    "# toxic_data_loader = retrieve_toxic_filtered_data(toxic_batch_size)\n",
    "owt_data_loader = retrieve_owt_data(owt_batch_size)\n",
    "\n",
    "with open(\"data/gpt2_means.pkl\", \"rb\") as f:\n",
    "    means = pickle.load(f)[0][0]\n",
    "\n",
    "model = load_demo_gpt2(means=means)\n",
    "epochs_left = 200\n",
    "log_every = 10\n",
    "lr = .05 # free\n",
    "weight_decay = 0\n",
    "clamp_every = 20 # 5 # free\n",
    "threshold = 0.5\n",
    "epochs_trained = 0\n",
    "regularization_strength = 1 # free\n",
    "\n",
    "mask_params = []\n",
    "param_names = []\n",
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        param_names.append(name)\n",
    "        mask_params.append(p)\n",
    "optimizer = AdamW(mask_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "losses = []\n",
    "num_ablated_edges = []\n",
    "alpha = 0.2 # free\n",
    "batch_size = toxic_batch_size + owt_batch_size\n",
    "demos = prepare_fixed_demo(tokenizer, batch_size, demo=\"\")\n",
    "owt_iter = cycle(owt_data_loader)\n",
    "edge_threshold = 100\n",
    "max_steps_per_epoch = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32124/790077214.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for e in tqdm(range(epochs_left)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4e62887bf74c1786185007c16d77f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=-20.480649948120117, ablated_edges=3850\n",
      "loss.item()=-21.82261085510254, ablated_edges=4690\n",
      "loss.item()=-21.94858169555664, ablated_edges=5151\n",
      "loss.item()=-23.0985107421875, ablated_edges=5411\n",
      "loss.item()=-23.775711059570312, ablated_edges=5631\n",
      "loss.item()=-23.016767501831055, ablated_edges=5748\n",
      "loss.item()=-22.896711349487305, ablated_edges=5899\n",
      "loss.item()=-22.47416114807129, ablated_edges=5988\n",
      "loss.item()=-22.715839385986328, ablated_edges=5994\n",
      "loss.item()=-22.140233993530273, ablated_edges=6025\n",
      "Epochs trained:  10\n",
      "Loss: -22.1402\n",
      "Total preserved: 5596.0112\n",
      "Edges ablated:  6025\n",
      "Toxic loss:  110.701171875\n",
      "OWT loss:  39.88070297241211\n",
      "Penalty:  0\n",
      "\n",
      "\n",
      "loss.item()=-24.003150939941406, ablated_edges=6032\n",
      "loss.item()=-22.38034439086914, ablated_edges=6116\n",
      "loss.item()=-23.817163467407227, ablated_edges=6087\n",
      "loss.item()=-23.070085525512695, ablated_edges=6153\n",
      "loss.item()=-21.958770751953125, ablated_edges=6152\n",
      "loss.item()=-22.717737197875977, ablated_edges=6155\n",
      "loss.item()=-22.999237060546875, ablated_edges=6149\n",
      "loss.item()=-20.391828536987305, ablated_edges=6167\n",
      "loss.item()=-23.744338989257812, ablated_edges=6147\n",
      "loss.item()=-22.728240966796875, ablated_edges=6153\n",
      "Epochs trained:  20\n",
      "Loss: -22.7282\n",
      "Total preserved: 5485.0952\n",
      "Edges ablated:  6156\n",
      "Toxic loss:  113.64120483398438\n",
      "OWT loss:  43.80976486206055\n",
      "Penalty:  0\n",
      "\n",
      "\n",
      "loss.item()=-21.102294921875, ablated_edges=6180\n",
      "loss.item()=-24.125940322875977, ablated_edges=5624\n",
      "loss.item()=-25.137529373168945, ablated_edges=4882\n",
      "loss.item()=-25.80465316772461, ablated_edges=4121\n",
      "loss.item()=-25.93012237548828, ablated_edges=3541\n",
      "loss.item()=-27.43266487121582, ablated_edges=3141\n",
      "loss.item()=-27.63208770751953, ablated_edges=2732\n",
      "loss.item()=-28.808761596679688, ablated_edges=2436\n",
      "loss.item()=-31.483543395996094, ablated_edges=2255\n",
      "loss.item()=-32.945472717285156, ablated_edges=2046\n",
      "Epochs trained:  30\n",
      "Loss: -32.9455\n",
      "Total preserved: 9428.7295\n",
      "Edges ablated:  2046\n",
      "Toxic loss:  122.29806518554688\n",
      "OWT loss:  35.00926971435547\n",
      "Penalty:  tensor(8.4859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-31.23771095275879, ablated_edges=1856\n",
      "loss.item()=-36.34928512573242, ablated_edges=1719\n",
      "loss.item()=-35.730499267578125, ablated_edges=1596\n",
      "loss.item()=-33.20258712768555, ablated_edges=1552\n",
      "loss.item()=-34.98409652709961, ablated_edges=1520\n",
      "loss.item()=-36.481990814208984, ablated_edges=1411\n",
      "loss.item()=-39.74237823486328, ablated_edges=1355\n",
      "loss.item()=-41.03523254394531, ablated_edges=1247\n",
      "loss.item()=-41.90154266357422, ablated_edges=1223\n",
      "loss.item()=-43.16987609863281, ablated_edges=1182\n",
      "Epochs trained:  40\n",
      "Loss: -43.1699\n",
      "Total preserved: 10311.7354\n",
      "Edges ablated:  1181\n",
      "Toxic loss:  117.88790893554688\n",
      "OWT loss:  40.94619369506836\n",
      "Penalty:  tensor(19.5923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-43.61274719238281, ablated_edges=1366\n",
      "loss.item()=-43.95195388793945, ablated_edges=1225\n",
      "loss.item()=-43.42486572265625, ablated_edges=1110\n",
      "loss.item()=-45.30971908569336, ablated_edges=1047\n",
      "loss.item()=-46.968780517578125, ablated_edges=988\n",
      "loss.item()=-49.99043273925781, ablated_edges=963\n",
      "loss.item()=-51.68903732299805, ablated_edges=929\n",
      "loss.item()=-50.193336486816406, ablated_edges=871\n",
      "loss.item()=-52.398841857910156, ablated_edges=860\n",
      "loss.item()=-52.70774841308594, ablated_edges=824\n",
      "Epochs trained:  50\n",
      "Loss: -52.7077\n",
      "Total preserved: 10675.6602\n",
      "Edges ablated:  824\n",
      "Toxic loss:  108.74166870117188\n",
      "OWT loss:  35.38203048706055\n",
      "Penalty:  tensor(30.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-53.733428955078125, ablated_edges=788\n",
      "loss.item()=-53.96168899536133, ablated_edges=773\n",
      "loss.item()=-58.58546447753906, ablated_edges=771\n",
      "loss.item()=-57.24082946777344, ablated_edges=741\n",
      "loss.item()=-59.55424499511719, ablated_edges=725\n",
      "loss.item()=-61.070045471191406, ablated_edges=735\n",
      "loss.item()=-61.30680847167969, ablated_edges=691\n",
      "loss.item()=-60.69633102416992, ablated_edges=687\n",
      "loss.item()=-64.4288558959961, ablated_edges=689\n",
      "loss.item()=-64.89801788330078, ablated_edges=663\n",
      "Epochs trained:  60\n",
      "Loss: -64.8980\n",
      "Total preserved: 10850.5273\n",
      "Edges ablated:  665\n",
      "Toxic loss:  112.90478515625\n",
      "OWT loss:  42.13862991333008\n",
      "Penalty:  tensor(42.3171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-65.05567932128906, ablated_edges=713\n",
      "loss.item()=-66.03462219238281, ablated_edges=656\n",
      "loss.item()=-66.6853256225586, ablated_edges=650\n",
      "loss.item()=-68.81932067871094, ablated_edges=640\n",
      "loss.item()=-70.39251708984375, ablated_edges=628\n",
      "loss.item()=-71.1367416381836, ablated_edges=634\n",
      "loss.item()=-71.98141479492188, ablated_edges=607\n",
      "loss.item()=-73.2716064453125, ablated_edges=609\n",
      "loss.item()=-72.52007293701172, ablated_edges=598\n",
      "loss.item()=-74.5515365600586, ablated_edges=585\n",
      "Epochs trained:  70\n",
      "Loss: -74.5515\n",
      "Total preserved: 10914.7988\n",
      "Edges ablated:  585\n",
      "Toxic loss:  105.34513854980469\n",
      "OWT loss:  39.82928466796875\n",
      "Penalty:  tensor(53.4825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-76.01055908203125, ablated_edges=576\n",
      "loss.item()=-76.25031280517578, ablated_edges=570\n",
      "loss.item()=-79.2000732421875, ablated_edges=540\n",
      "loss.item()=-81.73726654052734, ablated_edges=545\n",
      "loss.item()=-80.6122817993164, ablated_edges=524\n",
      "loss.item()=-80.3000259399414, ablated_edges=561\n",
      "loss.item()=-83.9059829711914, ablated_edges=527\n",
      "loss.item()=-84.67525482177734, ablated_edges=508\n",
      "loss.item()=-84.60946655273438, ablated_edges=505\n",
      "loss.item()=-86.72434997558594, ablated_edges=502\n",
      "Epochs trained:  80\n",
      "Loss: -86.7243\n",
      "Total preserved: 11045.3223\n",
      "Edges ablated:  500\n",
      "Toxic loss:  107.7846908569336\n",
      "OWT loss:  16.706832885742188\n",
      "Penalty:  tensor(65.1674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-86.80904388427734, ablated_edges=515\n",
      "loss.item()=-87.7846450805664, ablated_edges=482\n",
      "loss.item()=-90.043701171875, ablated_edges=501\n",
      "loss.item()=-89.26274108886719, ablated_edges=496\n",
      "loss.item()=-93.00202941894531, ablated_edges=481\n",
      "loss.item()=-92.96572875976562, ablated_edges=453\n",
      "loss.item()=-94.93186950683594, ablated_edges=458\n",
      "loss.item()=-96.21907806396484, ablated_edges=447\n",
      "loss.item()=-93.96258544921875, ablated_edges=460\n",
      "loss.item()=-99.28118896484375, ablated_edges=457\n",
      "Epochs trained:  90\n",
      "Loss: -99.2812\n",
      "Total preserved: 11080.4736\n",
      "Edges ablated:  457\n",
      "Toxic loss:  114.12960815429688\n",
      "OWT loss:  34.29189682006836\n",
      "Penalty:  tensor(76.4553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-99.48780822753906, ablated_edges=454\n",
      "loss.item()=-101.18717956542969, ablated_edges=440\n",
      "loss.item()=-101.39144134521484, ablated_edges=437\n",
      "loss.item()=-102.82841491699219, ablated_edges=436\n",
      "loss.item()=-103.47176361083984, ablated_edges=432\n",
      "loss.item()=-104.82067108154297, ablated_edges=447\n",
      "loss.item()=-107.63417053222656, ablated_edges=432\n",
      "loss.item()=-106.35736846923828, ablated_edges=413\n",
      "loss.item()=-109.26109313964844, ablated_edges=408\n",
      "loss.item()=-108.4085693359375, ablated_edges=407\n",
      "Epochs trained:  100\n",
      "Loss: -108.4086\n",
      "Total preserved: 11138.1631\n",
      "Edges ablated:  407\n",
      "Toxic loss:  102.08544921875\n",
      "OWT loss:  32.13884735107422\n",
      "Penalty:  tensor(87.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-110.86947631835938, ablated_edges=411\n",
      "loss.item()=-111.41643524169922, ablated_edges=401\n",
      "loss.item()=-112.15306854248047, ablated_edges=390\n",
      "loss.item()=-113.93539428710938, ablated_edges=384\n",
      "loss.item()=-116.119384765625, ablated_edges=410\n",
      "loss.item()=-115.78870391845703, ablated_edges=393\n",
      "loss.item()=-115.66548156738281, ablated_edges=380\n",
      "loss.item()=-117.8053970336914, ablated_edges=391\n",
      "loss.item()=-118.4743423461914, ablated_edges=386\n",
      "loss.item()=-120.82478332519531, ablated_edges=387\n",
      "Epochs trained:  110\n",
      "Loss: -120.8248\n",
      "Total preserved: 11166.5469\n",
      "Edges ablated:  387\n",
      "Toxic loss:  107.21250915527344\n",
      "OWT loss:  33.46048355102539\n",
      "Penalty:  tensor(99.3823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-122.32719421386719, ablated_edges=387\n",
      "loss.item()=-123.32633972167969, ablated_edges=378\n",
      "loss.item()=-125.035400390625, ablated_edges=381\n",
      "loss.item()=-125.04178619384766, ablated_edges=364\n",
      "loss.item()=-126.13179016113281, ablated_edges=366\n",
      "loss.item()=-127.10633087158203, ablated_edges=351\n",
      "loss.item()=-129.6733856201172, ablated_edges=343\n",
      "loss.item()=-127.81430053710938, ablated_edges=353\n",
      "loss.item()=-132.15184020996094, ablated_edges=347\n",
      "loss.item()=-130.21084594726562, ablated_edges=341\n",
      "Epochs trained:  120\n",
      "Loss: -130.2108\n",
      "Total preserved: 11203.9199\n",
      "Edges ablated:  341\n",
      "Toxic loss:  96.46018981933594\n",
      "OWT loss:  41.350181579589844\n",
      "Penalty:  tensor(110.9188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-131.83538818359375, ablated_edges=364\n",
      "loss.item()=-134.46331787109375, ablated_edges=343\n",
      "loss.item()=-134.9864044189453, ablated_edges=341\n",
      "loss.item()=-135.8531494140625, ablated_edges=317\n",
      "loss.item()=-137.00762939453125, ablated_edges=327\n",
      "loss.item()=-139.38082885742188, ablated_edges=323\n",
      "loss.item()=-138.7913818359375, ablated_edges=324\n",
      "loss.item()=-140.88717651367188, ablated_edges=317\n",
      "loss.item()=-143.84764099121094, ablated_edges=328\n",
      "loss.item()=-142.9226531982422, ablated_edges=318\n",
      "Epochs trained:  130\n",
      "Loss: -142.9227\n",
      "Total preserved: 11237.2578\n",
      "Edges ablated:  318\n",
      "Toxic loss:  102.18275451660156\n",
      "OWT loss:  37.266902923583984\n",
      "Penalty:  tensor(122.4861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-145.78611755371094, ablated_edges=314\n",
      "loss.item()=-147.33816528320312, ablated_edges=319\n",
      "loss.item()=-146.8932647705078, ablated_edges=312\n",
      "loss.item()=-147.34596252441406, ablated_edges=305\n",
      "loss.item()=-148.29620361328125, ablated_edges=303\n",
      "loss.item()=-150.6212158203125, ablated_edges=298\n",
      "loss.item()=-151.93820190429688, ablated_edges=302\n",
      "loss.item()=-151.6743927001953, ablated_edges=310\n",
      "loss.item()=-153.83865356445312, ablated_edges=298\n",
      "loss.item()=-154.25782775878906, ablated_edges=293\n",
      "Epochs trained:  140\n",
      "Loss: -154.2578\n",
      "Total preserved: 11263.5352\n",
      "Edges ablated:  293\n",
      "Toxic loss:  101.10885620117188\n",
      "OWT loss:  36.22592544555664\n",
      "Penalty:  tensor(134.0361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-159.72230529785156, ablated_edges=376\n",
      "loss.item()=-160.14785766601562, ablated_edges=340\n",
      "loss.item()=-162.7144775390625, ablated_edges=331\n",
      "loss.item()=-164.19757080078125, ablated_edges=326\n",
      "loss.item()=-166.15452575683594, ablated_edges=329\n",
      "loss.item()=-165.90382385253906, ablated_edges=306\n",
      "loss.item()=-166.40589904785156, ablated_edges=309\n",
      "loss.item()=-168.59152221679688, ablated_edges=302\n",
      "loss.item()=-170.99488830566406, ablated_edges=290\n",
      "loss.item()=-170.21632385253906, ablated_edges=295\n",
      "Epochs trained:  150\n",
      "Loss: -170.2163\n",
      "Total preserved: 11255.6299\n",
      "Edges ablated:  295\n",
      "Toxic loss:  125.09358215332031\n",
      "OWT loss:  84.54450225830078\n",
      "Penalty:  tensor(145.1976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-171.06900024414062, ablated_edges=288\n",
      "loss.item()=-172.679443359375, ablated_edges=294\n",
      "loss.item()=-174.82640075683594, ablated_edges=286\n",
      "loss.item()=-175.01815795898438, ablated_edges=289\n",
      "loss.item()=-176.76490783691406, ablated_edges=292\n",
      "loss.item()=-177.00791931152344, ablated_edges=282\n",
      "loss.item()=-179.27305603027344, ablated_edges=285\n",
      "loss.item()=-180.35377502441406, ablated_edges=285\n",
      "loss.item()=-182.1285400390625, ablated_edges=275\n",
      "loss.item()=-182.253662109375, ablated_edges=284\n",
      "Epochs trained:  160\n",
      "Loss: -182.2537\n",
      "Total preserved: 11275.6768\n",
      "Edges ablated:  286\n",
      "Toxic loss:  127.60868072509766\n",
      "OWT loss:  81.54010772705078\n",
      "Penalty:  tensor(156.7319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-183.94143676757812, ablated_edges=305\n",
      "loss.item()=-185.7282257080078, ablated_edges=287\n",
      "loss.item()=-186.57859802246094, ablated_edges=279\n",
      "loss.item()=-187.38157653808594, ablated_edges=278\n",
      "loss.item()=-188.1123046875, ablated_edges=284\n",
      "loss.item()=-189.70101928710938, ablated_edges=279\n",
      "loss.item()=-189.27732849121094, ablated_edges=274\n",
      "loss.item()=-193.08248901367188, ablated_edges=261\n",
      "loss.item()=-192.9862518310547, ablated_edges=266\n",
      "loss.item()=-194.29554748535156, ablated_edges=263\n",
      "Epochs trained:  170\n",
      "Loss: -194.2955\n",
      "Total preserved: 11294.8750\n",
      "Edges ablated:  263\n",
      "Toxic loss:  130.00955200195312\n",
      "OWT loss:  85.5885009765625\n",
      "Penalty:  tensor(168.2936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-195.89321899414062, ablated_edges=263\n",
      "loss.item()=-195.83615112304688, ablated_edges=262\n",
      "loss.item()=-197.47525024414062, ablated_edges=264\n",
      "loss.item()=-199.32601928710938, ablated_edges=256\n",
      "loss.item()=-199.59266662597656, ablated_edges=260\n",
      "loss.item()=-199.62989807128906, ablated_edges=259\n",
      "loss.item()=-201.86920166015625, ablated_edges=259\n",
      "loss.item()=-202.672119140625, ablated_edges=254\n",
      "loss.item()=-202.61732482910156, ablated_edges=255\n",
      "loss.item()=-206.75184631347656, ablated_edges=260\n",
      "Epochs trained:  180\n",
      "Loss: -206.7518\n",
      "Total preserved: 11301.4756\n",
      "Edges ablated:  259\n",
      "Toxic loss:  135.29197692871094\n",
      "OWT loss:  80.73320770263672\n",
      "Penalty:  tensor(179.6935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-205.9476318359375, ablated_edges=264\n",
      "loss.item()=-207.1592254638672, ablated_edges=257\n",
      "loss.item()=-209.91009521484375, ablated_edges=250\n",
      "loss.item()=-210.67361450195312, ablated_edges=253\n",
      "loss.item()=-211.36004638671875, ablated_edges=243\n",
      "loss.item()=-213.5864715576172, ablated_edges=248\n",
      "loss.item()=-213.10333251953125, ablated_edges=245\n",
      "loss.item()=-213.43917846679688, ablated_edges=245\n",
      "loss.item()=-215.059814453125, ablated_edges=230\n",
      "loss.item()=-217.2410888671875, ablated_edges=227\n",
      "Epochs trained:  190\n",
      "Loss: -217.2411\n",
      "Total preserved: 11329.9902\n",
      "Edges ablated:  227\n",
      "Toxic loss:  128.82138061523438\n",
      "OWT loss:  80.619384765625\n",
      "Penalty:  tensor(191.4768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-217.50445556640625, ablated_edges=233\n",
      "loss.item()=-219.2634735107422, ablated_edges=234\n",
      "loss.item()=-221.728271484375, ablated_edges=231\n",
      "loss.item()=-217.2378387451172, ablated_edges=230\n",
      "loss.item()=-221.33921813964844, ablated_edges=222\n",
      "loss.item()=-222.7264404296875, ablated_edges=216\n",
      "loss.item()=-225.81988525390625, ablated_edges=222\n",
      "loss.item()=-226.8464813232422, ablated_edges=215\n",
      "loss.item()=-228.03790283203125, ablated_edges=217\n",
      "loss.item()=-228.7856903076172, ablated_edges=210\n",
      "Epochs trained:  200\n",
      "Loss: -228.7857\n",
      "Total preserved: 11349.1436\n",
      "Edges ablated:  212\n",
      "Toxic loss:  128.1802215576172\n",
      "OWT loss:  78.99507141113281\n",
      "Penalty:  tensor(203.1496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     prev_params \u001b[39m=\u001b[39m mask_params\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m epochs_left \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mcontinue training for this number of epochs: \u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m log_every \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mset log frequency\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m edge_threshold \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mset edge threshold\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "old_mask_params = {}\n",
    "def duplicate_mask_params(mask_params):\n",
    "    new_mask_params = []\n",
    "    for p in mask_params:\n",
    "        new_mask_params.append(p.data.cpu())\n",
    "    return new_mask_params\n",
    "\n",
    "prev_params = None\n",
    "while epochs_left >= 0:\n",
    "    for e in tqdm(range(epochs_left)):\n",
    "        for c, batch in enumerate(toxic_data_loader):\n",
    "            if c > max_steps_per_epoch:\n",
    "                break\n",
    "\n",
    "            # print(batch[\"text\"])\n",
    "            total_preserving = 0\n",
    "            ablated_edges = 0\n",
    "            penalty = 0\n",
    "            for p in mask_params:\n",
    "                total_preserving += p.sum()\n",
    "                ablated_edges += p[p.data < 0.5].shape[0]\n",
    "                penalty += max(0, p.sum() * (epochs_trained-20) / 10000) # why 2000? free\n",
    "\n",
    "            # demos = batch[:, :FILTER_DEMO_LEN]\n",
    "            # completions = batch[:, FILTER_DEMO_LEN:]\n",
    "\n",
    "            # tox_loss = infer_batch(model, criterion, completions, toxic_batch_size, demos)\n",
    "            # owt_loss = infer_batch(model, criterion, next(owt_iter)['tokens'], owt_batch_size, fixed_demos)\n",
    "            tox_loss, owt_loss = infer_batch_with_owt(model, criterion, batch, next(owt_iter), batch_size, demos, access_toxic_pos=-1)\n",
    "            # print(f\"{tox_loss=}, {owt_loss=}\")\n",
    "            loss = -1 * (regularization_strength * penalty + alpha * tox_loss) #+ owt_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "            num_ablated_edges.append(ablated_edges)\n",
    "            for p in mask_params:\n",
    "                p.data.clamp_(0,1)\n",
    "        print(f\"{loss.item()=}, {ablated_edges=}\")\n",
    "        epochs_trained += 1\n",
    "        if epochs_trained % clamp_every == 0:\n",
    "            ablated_edges = 0\n",
    "            for p in mask_params:\n",
    "                p.data[p.data < threshold] = 0\n",
    "                p.data[p.data >= threshold] = 1\n",
    "                ablated_edges += p[p.data < 0.5].shape[0]\n",
    "        if epochs_trained % log_every == 0:\n",
    "            print(\"Epochs trained: \", epochs_trained)\n",
    "            print(f\"Loss: {loss.item():.4f}\")\n",
    "            print(f\"Total preserved: {total_preserving:.4f}\")\n",
    "            print(\"Edges ablated: \", ablated_edges)\n",
    "            print(\"Toxic loss: \", tox_loss.item())\n",
    "            print(\"OWT loss: \", owt_loss.item())\n",
    "            print(\"Penalty: \", penalty)\n",
    "            # if input('evaluate? (y)') == 'y':\n",
    "            #     evaluate_model(model, toxic_batches=1, owt_batches=1)\n",
    "            print(\"\\n\")\n",
    "            old_mask_params[epochs_trained] = duplicate_mask_params(mask_params)\n",
    "                \n",
    "        if epochs_trained > 50 and ablated_edges < edge_threshold:\n",
    "            break\n",
    "        prev_params = mask_params\n",
    "    epochs_left = int(input('continue training for this number of epochs: '))\n",
    "    log_every = int(input('set log frequency'))\n",
    "    edge_threshold = int(input('set edge threshold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/alternative_necessary_masks_params_dict_lambda=1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(old_mask_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different alternative: sufficient but not necessary\n",
    "Trains with an inverted loss function. This loss function encourages sparsity (as opposed to discouraging) and wants model to ablate everything but the necessary circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_batch_size = 1 # so that we can just access the last sequence position without worrying about padding\n",
    "owt_batch_size = 1\n",
    "context_length = CONTEXT_LENGTH\n",
    "\n",
    "toxic_data_loader = retrieve_toxic_data(toxic_batch_size, context_length, tokenizer, tokenize=False, num_points=None)\n",
    "# toxic_data_loader = retrieve_toxic_filtered_data(toxic_batch_size)\n",
    "owt_data_loader = retrieve_owt_data(owt_batch_size)\n",
    "\n",
    "with open(\"data/gpt2_means.pkl\", \"rb\") as f:\n",
    "    means = pickle.load(f)[0][0]\n",
    "\n",
    "model = load_demo_gpt2(means=means)\n",
    "epochs_left = 200\n",
    "log_every = 10\n",
    "lr = .05 # free\n",
    "weight_decay = 0\n",
    "clamp_every = 20 # 5 # free\n",
    "threshold = 0.5\n",
    "epochs_trained = 0\n",
    "regularization_strength = 1 # free\n",
    "\n",
    "mask_params = []\n",
    "param_names = []\n",
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        param_names.append(name)\n",
    "        mask_params.append(p)\n",
    "optimizer = AdamW(mask_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "losses = []\n",
    "num_ablated_edges = []\n",
    "alpha = 0.2 # free\n",
    "batch_size = toxic_batch_size + owt_batch_size\n",
    "demos = prepare_fixed_demo(tokenizer, batch_size, demo=\"\")\n",
    "owt_iter = cycle(owt_data_loader)\n",
    "edge_threshold = 100\n",
    "max_steps_per_epoch = 100\n",
    "\n",
    "\n",
    "old_mask_params = {}\n",
    "def duplicate_mask_params(mask_params):\n",
    "    new_mask_params = []\n",
    "    for p in mask_params:\n",
    "        new_mask_params.append(p.data.cpu())\n",
    "    return new_mask_params\n",
    "\n",
    "prev_params = None\n",
    "while epochs_left >= 0:\n",
    "    for e in tqdm(range(epochs_left)):\n",
    "        for c, batch in enumerate(toxic_data_loader):\n",
    "            if c > max_steps_per_epoch:\n",
    "                break\n",
    "\n",
    "            # print(batch[\"text\"])\n",
    "            total_preserving = 0\n",
    "            ablated_edges = 0\n",
    "            penalty = 0\n",
    "            for p in mask_params:\n",
    "                total_preserving += p.sum()\n",
    "                ablated_edges += p[p.data < 0.5].shape[0]\n",
    "                penalty += max(0, p.sum() * (epochs_trained-20) / 10000) # why 2000? free\n",
    "\n",
    "            tox_loss, owt_loss = infer_batch_with_owt(model, criterion, batch, next(owt_iter), batch_size, demos, access_toxic_pos=-1)\n",
    "            # print(f\"{tox_loss=}, {owt_loss=}\")\n",
    "            loss = regularization_strength * penalty + alpha * tox_loss # inverted loss function #+ owt_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "            num_ablated_edges.append(ablated_edges)\n",
    "            for p in mask_params:\n",
    "                p.data.clamp_(0,1)\n",
    "        print(f\"{loss.item()=}, {ablated_edges=}\")\n",
    "        epochs_trained += 1\n",
    "        if epochs_trained % clamp_every == 0:\n",
    "            ablated_edges = 0\n",
    "            for p in mask_params:\n",
    "                p.data[p.data < threshold] = 0\n",
    "                p.data[p.data >= threshold] = 1\n",
    "                ablated_edges += p[p.data < 0.5].shape[0]\n",
    "        if epochs_trained % log_every == 0:\n",
    "            print(\"Epochs trained: \", epochs_trained)\n",
    "            print(f\"Loss: {loss.item():.4f}\")\n",
    "            print(f\"Total preserved: {total_preserving:.4f}\")\n",
    "            print(\"Edges ablated: \", ablated_edges)\n",
    "            print(\"Toxic loss: \", tox_loss.item())\n",
    "            print(\"OWT loss: \", owt_loss.item())\n",
    "            print(\"Penalty: \", penalty)\n",
    "            # if input('evaluate? (y)') == 'y':\n",
    "            #     evaluate_model(model, toxic_batches=1, owt_batches=1)\n",
    "            print(\"\\n\")\n",
    "            old_mask_params[epochs_trained] = duplicate_mask_params(mask_params)\n",
    "                \n",
    "        if epochs_trained > 50 and ablated_edges < edge_threshold:\n",
    "            break\n",
    "        prev_params = mask_params\n",
    "\n",
    "    epochs_left = -1\n",
    "    # epochs_left = int(input('continue training for this number of epochs: '))\n",
    "    # log_every = int(input('set log frequency'))\n",
    "    # edge_threshold = int(input('set edge threshold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/alternative_sufficient_masks_params_dict_lambda=1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(old_mask_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train mask over known circuit\n",
    "Train mask over the circuit from the paper, as given by a run of ACDC++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embed': tensor([]),\n",
       " 'a0.0': tensor([1.]),\n",
       " 'a0.1': tensor([0.]),\n",
       " 'a0.2': tensor([1.]),\n",
       " 'a0.3': tensor([0.]),\n",
       " 'a0.4': tensor([1.]),\n",
       " 'a0.5': tensor([0.]),\n",
       " 'a0.6': tensor([1.]),\n",
       " 'a0.7': tensor([1.]),\n",
       " 'a0.8': tensor([1.]),\n",
       " 'a0.9': tensor([1.]),\n",
       " 'a0.10': tensor([0.]),\n",
       " 'a0.11': tensor([1.]),\n",
       " 'm0': tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.]),\n",
       " 'a1.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a1.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'm1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a2.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'm2': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1.]),\n",
       " 'a3.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.]),\n",
       " 'a3.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'a3.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]),\n",
       " 'm3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a4.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'm4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.]),\n",
       " 'a5.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.]),\n",
       " 'a5.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a5.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'm5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         0., 1., 0., 0., 0., 1.]),\n",
       " 'a6.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 1., 1., 1.]),\n",
       " 'a6.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.9': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 0.]),\n",
       " 'a6.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a6.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'm6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "         1.]),\n",
       " 'a7.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.9': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 0.]),\n",
       " 'a7.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'a7.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]),\n",
       " 'm7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.]),\n",
       " 'a8.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a8.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'm8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1.]),\n",
       " 'a9.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a9.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a9.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a9.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a9.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]),\n",
       " 'a9.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a9.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a9.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 0.]),\n",
       " 'a9.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a9.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]),\n",
       " 'a9.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a9.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'm9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1.]),\n",
       " 'a10.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 1.]),\n",
       " 'a10.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.7': tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 1.]),\n",
       " 'a10.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'a10.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1.]),\n",
       " 'm10': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.1': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.2': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.3': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.4': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.5': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.6': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.7': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.8': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.9': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'a11.10': tensor([1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.]),\n",
       " 'a11.11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'm11': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'output': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mask_utils import get_nodes_and_edges\n",
    "with open(\"models/acdcpp_mask_params.pkl\", \"rb\") as f:\n",
    "    acdc_mask_params = pickle.load(f)\n",
    "\n",
    "_, _, acdc_Edges, acdc_mask_dict = get_nodes_and_edges(mask_params=acdc_mask_params)\n",
    "acdc_mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([157])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acdc_mask_dict['output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22863/1329432646.py:48: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for e in tqdm(range(epochs_left)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10673f0ad7234b04a3294330b8b5f2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=1.5056736469268799, ablated_edges=80\n",
      "loss.item()=-0.500084400177002, ablated_edges=87\n",
      "loss.item()=-0.0825948715209961, ablated_edges=87\n",
      "loss.item()=0.15455102920532227, ablated_edges=88\n",
      "loss.item()=0.7475423812866211, ablated_edges=95\n",
      "loss.item()=0.7848529815673828, ablated_edges=94\n",
      "loss.item()=0.06402826309204102, ablated_edges=98\n",
      "loss.item()=-0.9390511512756348, ablated_edges=96\n",
      "loss.item()=0.6501531600952148, ablated_edges=98\n",
      "loss.item()=0.626798152923584, ablated_edges=98\n",
      "Epochs trained:  10\n",
      "Loss: 0.6268\n",
      "Total preserved: 11512.8232\n",
      "Edges ablated:  98\n",
      "Toxic loss:  23.036602020263672\n",
      "OWT loss:  5.234118461608887\n",
      "Penalty:  0\n",
      "\n",
      "\n",
      "loss.item()=-3.0186614990234375, ablated_edges=103\n",
      "loss.item()=-0.8208189010620117, ablated_edges=93\n",
      "loss.item()=0.038724422454833984, ablated_edges=94\n",
      "loss.item()=-0.08931589126586914, ablated_edges=95\n",
      "loss.item()=-0.5814499855041504, ablated_edges=98\n",
      "loss.item()=-0.1508636474609375, ablated_edges=102\n",
      "loss.item()=2.3883941173553467, ablated_edges=98\n",
      "loss.item()=1.5119729042053223, ablated_edges=96\n",
      "loss.item()=-0.7001581192016602, ablated_edges=100\n",
      "loss.item()=-0.5811986923217773, ablated_edges=97\n",
      "Epochs trained:  20\n",
      "Loss: -0.5812\n",
      "Total preserved: 11511.8525\n",
      "Edges ablated:  97\n",
      "Toxic loss:  27.467458724975586\n",
      "OWT loss:  4.912292957305908\n",
      "Penalty:  0\n",
      "\n",
      "\n",
      "loss.item()=1.1091012954711914, ablated_edges=100\n",
      "loss.item()=-0.7198200225830078, ablated_edges=98\n",
      "loss.item()=-1.066877841949463, ablated_edges=100\n",
      "loss.item()=-4.244425296783447, ablated_edges=105\n",
      "loss.item()=-5.552443981170654, ablated_edges=98\n",
      "loss.item()=-6.534358024597168, ablated_edges=91\n",
      "loss.item()=-7.882603168487549, ablated_edges=89\n",
      "loss.item()=-8.790934562683105, ablated_edges=88\n",
      "loss.item()=-8.656744003295898, ablated_edges=87\n",
      "loss.item()=-8.970634460449219, ablated_edges=89\n",
      "Epochs trained:  30\n",
      "Loss: -8.9706\n",
      "Total preserved: 11524.6582\n",
      "Edges ablated:  89\n",
      "Toxic loss:  19.04596519470215\n",
      "OWT loss:  5.210751056671143\n",
      "Penalty:  tensor(10.3722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-10.965009689331055, ablated_edges=88\n",
      "loss.item()=-13.547128677368164, ablated_edges=90\n",
      "loss.item()=-13.717792510986328, ablated_edges=87\n",
      "loss.item()=-16.68755340576172, ablated_edges=86\n",
      "loss.item()=-16.444446563720703, ablated_edges=82\n",
      "loss.item()=-16.821895599365234, ablated_edges=82\n",
      "loss.item()=-17.48927116394043, ablated_edges=80\n",
      "loss.item()=-21.36284828186035, ablated_edges=81\n",
      "loss.item()=-21.52306365966797, ablated_edges=80\n",
      "loss.item()=-22.231990814208984, ablated_edges=77\n",
      "Epochs trained:  40\n",
      "Loss: -22.2320\n",
      "Total preserved: 11534.5127\n",
      "Edges ablated:  78\n",
      "Toxic loss:  26.378662109375\n",
      "OWT loss:  4.959319114685059\n",
      "Penalty:  tensor(21.9156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-22.69232940673828, ablated_edges=77\n",
      "loss.item()=-23.534677505493164, ablated_edges=78\n",
      "loss.item()=-25.442670822143555, ablated_edges=76\n",
      "loss.item()=-27.155630111694336, ablated_edges=79\n",
      "loss.item()=-28.782812118530273, ablated_edges=76\n",
      "loss.item()=-28.164342880249023, ablated_edges=77\n",
      "loss.item()=-29.027385711669922, ablated_edges=72\n",
      "loss.item()=-30.837371826171875, ablated_edges=80\n",
      "loss.item()=-32.40890121459961, ablated_edges=72\n",
      "loss.item()=-32.99948501586914, ablated_edges=72\n",
      "Epochs trained:  50\n",
      "Loss: -32.9995\n",
      "Total preserved: 11537.1387\n",
      "Edges ablated:  72\n",
      "Toxic loss:  25.70037269592285\n",
      "OWT loss:  5.598297119140625\n",
      "Penalty:  tensor(33.4577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-33.814735412597656, ablated_edges=70\n",
      "loss.item()=-34.977874755859375, ablated_edges=74\n",
      "loss.item()=-38.72045135498047, ablated_edges=76\n",
      "loss.item()=-38.59954833984375, ablated_edges=72\n",
      "loss.item()=-37.44197082519531, ablated_edges=75\n",
      "loss.item()=-40.775421142578125, ablated_edges=69\n",
      "loss.item()=-39.43312454223633, ablated_edges=69\n",
      "loss.item()=-43.922523498535156, ablated_edges=70\n",
      "loss.item()=-44.29679870605469, ablated_edges=63\n",
      "loss.item()=-44.6660270690918, ablated_edges=69\n",
      "Epochs trained:  60\n",
      "Loss: -44.6660\n",
      "Total preserved: 11543.3457\n",
      "Edges ablated:  68\n",
      "Toxic loss:  24.17945098876953\n",
      "OWT loss:  5.188914775848389\n",
      "Penalty:  tensor(45.0191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-45.43226623535156, ablated_edges=68\n",
      "loss.item()=-47.554931640625, ablated_edges=67\n",
      "loss.item()=-48.48405456542969, ablated_edges=70\n",
      "loss.item()=-49.8265495300293, ablated_edges=67\n",
      "loss.item()=-51.74678421020508, ablated_edges=66\n",
      "loss.item()=-51.73463821411133, ablated_edges=69\n",
      "loss.item()=-52.265323638916016, ablated_edges=70\n",
      "loss.item()=-54.762516021728516, ablated_edges=71\n",
      "loss.item()=-55.7078971862793, ablated_edges=68\n",
      "loss.item()=-56.24128723144531, ablated_edges=67\n",
      "Epochs trained:  70\n",
      "Loss: -56.2413\n",
      "Total preserved: 11541.6113\n",
      "Edges ablated:  67\n",
      "Toxic loss:  23.93475341796875\n",
      "OWT loss:  5.099553108215332\n",
      "Penalty:  tensor(56.5539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-57.00583267211914, ablated_edges=69\n",
      "loss.item()=-57.7839469909668, ablated_edges=70\n",
      "loss.item()=-58.821163177490234, ablated_edges=67\n",
      "loss.item()=-61.0757942199707, ablated_edges=66\n",
      "loss.item()=-63.463558197021484, ablated_edges=66\n",
      "loss.item()=-64.74162292480469, ablated_edges=62\n",
      "loss.item()=-65.59223175048828, ablated_edges=61\n",
      "loss.item()=-65.37863159179688, ablated_edges=66\n",
      "loss.item()=-66.93404388427734, ablated_edges=61\n",
      "loss.item()=-67.35196685791016, ablated_edges=66\n",
      "Epochs trained:  80\n",
      "Loss: -67.3520\n",
      "Total preserved: 11547.4160\n",
      "Edges ablated:  64\n",
      "Toxic loss:  22.907915115356445\n",
      "OWT loss:  5.359364986419678\n",
      "Penalty:  tensor(68.1298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-70.22889709472656, ablated_edges=59\n",
      "loss.item()=-69.60752868652344, ablated_edges=62\n",
      "loss.item()=-71.21782684326172, ablated_edges=64\n",
      "loss.item()=-72.4986801147461, ablated_edges=64\n",
      "loss.item()=-74.5802001953125, ablated_edges=66\n",
      "loss.item()=-74.36848449707031, ablated_edges=65\n",
      "loss.item()=-76.47356414794922, ablated_edges=63\n",
      "loss.item()=-78.4028549194336, ablated_edges=63\n",
      "loss.item()=-77.62654876708984, ablated_edges=66\n",
      "loss.item()=-80.140625, ablated_edges=64\n",
      "Epochs trained:  90\n",
      "Loss: -80.1406\n",
      "Total preserved: 11547.1406\n",
      "Edges ablated:  64\n",
      "Toxic loss:  23.180822372436523\n",
      "OWT loss:  4.170817852020264\n",
      "Penalty:  tensor(79.6753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-82.50818634033203, ablated_edges=66\n",
      "loss.item()=-81.01814270019531, ablated_edges=64\n",
      "loss.item()=-83.3720474243164, ablated_edges=66\n",
      "loss.item()=-83.98469543457031, ablated_edges=58\n",
      "loss.item()=-87.44886016845703, ablated_edges=61\n",
      "loss.item()=-86.34146881103516, ablated_edges=58\n",
      "loss.item()=-85.54612731933594, ablated_edges=57\n",
      "loss.item()=-90.238525390625, ablated_edges=54\n",
      "loss.item()=-90.92143249511719, ablated_edges=54\n",
      "loss.item()=-92.84722137451172, ablated_edges=57\n",
      "Epochs trained:  100\n",
      "Loss: -92.8472\n",
      "Total preserved: 11554.1641\n",
      "Edges ablated:  57\n",
      "Toxic loss:  33.43305587768555\n",
      "OWT loss:  5.11730432510376\n",
      "Penalty:  tensor(91.2779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-91.27748107910156, ablated_edges=59\n",
      "loss.item()=-93.88461303710938, ablated_edges=54\n",
      "loss.item()=-94.77798461914062, ablated_edges=50\n",
      "loss.item()=-94.69718933105469, ablated_edges=52\n",
      "loss.item()=-95.52283477783203, ablated_edges=53\n",
      "loss.item()=-97.91181182861328, ablated_edges=58\n",
      "loss.item()=-100.29170989990234, ablated_edges=53\n",
      "loss.item()=-101.28544616699219, ablated_edges=52\n",
      "loss.item()=-99.9444808959961, ablated_edges=54\n",
      "loss.item()=-102.86627197265625, ablated_edges=53\n",
      "Epochs trained:  110\n",
      "Loss: -102.8663\n",
      "Total preserved: 11557.9971\n",
      "Edges ablated:  53\n",
      "Toxic loss:  28.86589813232422\n",
      "OWT loss:  5.773064613342285\n",
      "Penalty:  tensor(102.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-103.58384704589844, ablated_edges=52\n",
      "loss.item()=-105.84606170654297, ablated_edges=52\n",
      "loss.item()=-107.2335433959961, ablated_edges=53\n",
      "loss.item()=-106.85431671142578, ablated_edges=53\n",
      "loss.item()=-109.91695404052734, ablated_edges=52\n",
      "loss.item()=-110.24185943603516, ablated_edges=54\n",
      "loss.item()=-111.40071105957031, ablated_edges=50\n",
      "loss.item()=-112.56986999511719, ablated_edges=50\n",
      "loss.item()=-113.40050506591797, ablated_edges=53\n",
      "loss.item()=-113.72864532470703, ablated_edges=52\n",
      "Epochs trained:  120\n",
      "Loss: -113.7286\n",
      "Total preserved: 11557.8770\n",
      "Edges ablated:  52\n",
      "Toxic loss:  28.943449020385742\n",
      "OWT loss:  6.483026027679443\n",
      "Penalty:  tensor(114.4230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-116.54255676269531, ablated_edges=53\n",
      "loss.item()=-116.79327392578125, ablated_edges=51\n",
      "loss.item()=-115.19482421875, ablated_edges=51\n",
      "loss.item()=-118.75401306152344, ablated_edges=53\n",
      "loss.item()=-122.14277648925781, ablated_edges=49\n",
      "loss.item()=-121.06953430175781, ablated_edges=48\n",
      "loss.item()=-122.05601501464844, ablated_edges=49\n",
      "loss.item()=-123.47509002685547, ablated_edges=48\n",
      "loss.item()=-124.31399536132812, ablated_edges=50\n",
      "loss.item()=-127.36456298828125, ablated_edges=46\n",
      "Epochs trained:  130\n",
      "Loss: -127.3646\n",
      "Total preserved: 11562.5859\n",
      "Edges ablated:  46\n",
      "Toxic loss:  32.48900604248047\n",
      "OWT loss:  5.165423393249512\n",
      "Penalty:  tensor(126.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-126.47238159179688, ablated_edges=47\n",
      "loss.item()=-128.5781707763672, ablated_edges=49\n",
      "loss.item()=-130.5258331298828, ablated_edges=46\n",
      "loss.item()=-129.74996948242188, ablated_edges=47\n",
      "loss.item()=-132.48599243164062, ablated_edges=48\n",
      "loss.item()=-133.76837158203125, ablated_edges=47\n",
      "loss.item()=-132.95957946777344, ablated_edges=46\n",
      "loss.item()=-133.96261596679688, ablated_edges=45\n",
      "loss.item()=-135.52638244628906, ablated_edges=47\n",
      "loss.item()=-137.492431640625, ablated_edges=50\n",
      "Epochs trained:  140\n",
      "Loss: -137.4924\n",
      "Total preserved: 11560.9385\n",
      "Edges ablated:  50\n",
      "Toxic loss:  27.15222930908203\n",
      "OWT loss:  5.513188362121582\n",
      "Penalty:  tensor(137.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-138.09088134765625, ablated_edges=46\n",
      "loss.item()=-139.6414031982422, ablated_edges=46\n",
      "loss.item()=-140.9293975830078, ablated_edges=45\n",
      "loss.item()=-141.51370239257812, ablated_edges=49\n",
      "loss.item()=-144.06930541992188, ablated_edges=46\n",
      "loss.item()=-143.3538055419922, ablated_edges=47\n",
      "loss.item()=-146.1291046142578, ablated_edges=44\n",
      "loss.item()=-146.28192138671875, ablated_edges=47\n",
      "loss.item()=-148.14944458007812, ablated_edges=48\n",
      "loss.item()=-150.17247009277344, ablated_edges=50\n",
      "Epochs trained:  150\n",
      "Loss: -150.1725\n",
      "Total preserved: 11561.4805\n",
      "Edges ablated:  50\n",
      "Toxic loss:  33.0401725769043\n",
      "OWT loss:  5.578667640686035\n",
      "Penalty:  tensor(149.1431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-152.55580139160156, ablated_edges=49\n",
      "loss.item()=-151.85586547851562, ablated_edges=49\n",
      "loss.item()=-153.99522399902344, ablated_edges=46\n",
      "loss.item()=-153.05007934570312, ablated_edges=47\n",
      "loss.item()=-155.26657104492188, ablated_edges=45\n",
      "loss.item()=-155.52505493164062, ablated_edges=49\n",
      "loss.item()=-158.27174377441406, ablated_edges=46\n",
      "loss.item()=-158.82046508789062, ablated_edges=43\n",
      "loss.item()=-159.7530059814453, ablated_edges=48\n",
      "loss.item()=-161.92526245117188, ablated_edges=46\n",
      "Epochs trained:  160\n",
      "Loss: -161.9253\n",
      "Total preserved: 11562.2822\n",
      "Edges ablated:  46\n",
      "Toxic loss:  33.64940643310547\n",
      "OWT loss:  5.520321846008301\n",
      "Penalty:  tensor(160.7157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-161.7630157470703, ablated_edges=43\n",
      "loss.item()=-162.72824096679688, ablated_edges=43\n",
      "loss.item()=-163.37709045410156, ablated_edges=47\n",
      "loss.item()=-164.8791961669922, ablated_edges=44\n",
      "loss.item()=-167.94241333007812, ablated_edges=45\n",
      "loss.item()=-168.17257690429688, ablated_edges=46\n",
      "loss.item()=-168.0404052734375, ablated_edges=47\n",
      "loss.item()=-169.7171630859375, ablated_edges=49\n",
      "loss.item()=-171.64768981933594, ablated_edges=46\n",
      "loss.item()=-174.03814697265625, ablated_edges=43\n",
      "Epochs trained:  170\n",
      "Loss: -174.0381\n",
      "Total preserved: 11564.3203\n",
      "Edges ablated:  43\n",
      "Toxic loss:  39.49759292602539\n",
      "OWT loss:  6.16975736618042\n",
      "Penalty:  tensor(172.3084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-174.89840698242188, ablated_edges=45\n",
      "loss.item()=-174.6654510498047, ablated_edges=48\n",
      "loss.item()=-174.72088623046875, ablated_edges=45\n",
      "loss.item()=-178.4546661376953, ablated_edges=46\n",
      "loss.item()=-177.6720428466797, ablated_edges=47\n",
      "loss.item()=-179.65830993652344, ablated_edges=48\n",
      "loss.item()=-179.35630798339844, ablated_edges=41\n",
      "loss.item()=-183.06385803222656, ablated_edges=44\n",
      "loss.item()=-184.6969757080078, ablated_edges=46\n",
      "loss.item()=-184.05078125, ablated_edges=44\n",
      "Epochs trained:  180\n",
      "Loss: -184.0508\n",
      "Total preserved: 11566.2373\n",
      "Edges ablated:  44\n",
      "Toxic loss:  28.797325134277344\n",
      "OWT loss:  5.611840724945068\n",
      "Penalty:  tensor(183.9032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-184.4897003173828, ablated_edges=47\n",
      "loss.item()=-185.37271118164062, ablated_edges=46\n",
      "loss.item()=-186.9844207763672, ablated_edges=43\n",
      "loss.item()=-188.4407501220703, ablated_edges=46\n",
      "loss.item()=-189.3105010986328, ablated_edges=44\n",
      "loss.item()=-191.02035522460938, ablated_edges=44\n",
      "loss.item()=-191.65814208984375, ablated_edges=43\n",
      "loss.item()=-191.11868286132812, ablated_edges=45\n",
      "loss.item()=-195.22610473632812, ablated_edges=44\n",
      "loss.item()=-195.29010009765625, ablated_edges=44\n",
      "Epochs trained:  190\n",
      "Loss: -195.2901\n",
      "Total preserved: 11565.8291\n",
      "Edges ablated:  44\n",
      "Toxic loss:  25.891029357910156\n",
      "OWT loss:  5.3506364822387695\n",
      "Penalty:  tensor(195.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-197.07337951660156, ablated_edges=46\n",
      "loss.item()=-197.45147705078125, ablated_edges=47\n",
      "loss.item()=-199.31268310546875, ablated_edges=44\n",
      "loss.item()=-198.38023376464844, ablated_edges=43\n",
      "loss.item()=-201.58419799804688, ablated_edges=44\n",
      "loss.item()=-199.99661254882812, ablated_edges=44\n",
      "loss.item()=-202.88490295410156, ablated_edges=46\n",
      "loss.item()=-203.29649353027344, ablated_edges=44\n",
      "loss.item()=-205.46502685546875, ablated_edges=41\n",
      "loss.item()=-207.99468994140625, ablated_edges=43\n",
      "Epochs trained:  200\n",
      "Loss: -207.9947\n",
      "Total preserved: 11567.3525\n",
      "Edges ablated:  43\n",
      "Toxic loss:  30.689029693603516\n",
      "OWT loss:  5.198721885681152\n",
      "Penalty:  tensor(207.0556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m     prev_params \u001b[39m=\u001b[39m mask_params\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m epochs_left \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcontinue training for this number of epochs: \u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m log_every \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mset log frequency\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/alternative_masks.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m edge_threshold \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mset edge threshold\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "toxic_batch_size = 1 # so that we can just access the last sequence position without worrying about padding\n",
    "owt_batch_size = 5\n",
    "context_length = CONTEXT_LENGTH\n",
    "\n",
    "toxic_data_loader = retrieve_toxic_data(toxic_batch_size, context_length, tokenizer, tokenize=False, num_points=None)\n",
    "# toxic_data_loader = retrieve_toxic_filtered_data(toxic_batch_size)\n",
    "owt_data_loader = retrieve_owt_data(owt_batch_size)\n",
    "\n",
    "with open(\"data/gpt2_means.pkl\", \"rb\") as f:\n",
    "    means = pickle.load(f)[0][0]\n",
    "\n",
    "model = load_demo_gpt2(means=means, mask_dict_superset=acdc_mask_dict)\n",
    "epochs_left = 200\n",
    "log_every = 10\n",
    "lr = .05 # free\n",
    "weight_decay = 0\n",
    "clamp_every = 20 # 5 # free\n",
    "threshold = 0.5\n",
    "epochs_trained = 0\n",
    "regularization_strength = 1 # free\n",
    "\n",
    "mask_params = []\n",
    "param_names = []\n",
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        param_names.append(name)\n",
    "        mask_params.append(p)\n",
    "optimizer = AdamW(mask_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "losses = []\n",
    "num_ablated_edges = []\n",
    "alpha = 0.2 # free\n",
    "batch_size = toxic_batch_size + owt_batch_size\n",
    "demos = prepare_fixed_demo(tokenizer, batch_size, demo=\"\")\n",
    "owt_iter = cycle(owt_data_loader)\n",
    "edge_threshold = 0\n",
    "max_steps_per_epoch = 100\n",
    "\n",
    "old_mask_params = {}\n",
    "def duplicate_mask_params(mask_params):\n",
    "    new_mask_params = []\n",
    "    for p in mask_params:\n",
    "        new_mask_params.append(p.data.cpu())\n",
    "    return new_mask_params\n",
    "\n",
    "prev_params = None\n",
    "while epochs_left >= 0:\n",
    "    for e in tqdm(range(epochs_left)):\n",
    "        for c, batch in enumerate(toxic_data_loader):\n",
    "            if c > max_steps_per_epoch:\n",
    "                break\n",
    "\n",
    "            # print(batch[\"text\"])\n",
    "            total_preserving = 0\n",
    "            ablated_edges = 0\n",
    "            penalty = 0\n",
    "            for p in mask_params:\n",
    "                total_preserving += p.sum()\n",
    "                ablated_edges += p[p.data < 0.5].shape[0]\n",
    "                penalty += max(0, p.sum() * (epochs_trained-20) / 10000) # why 2000? free\n",
    "            # print(f\"{ablated_edges=}\")\n",
    "            # demos = batch[:, :FILTER_DEMO_LEN]\n",
    "            # completions = batch[:, FILTER_DEMO_LEN:]\n",
    "\n",
    "            # tox_loss = infer_batch(model, criterion, completions, toxic_batch_size, demos)\n",
    "            # owt_loss = infer_batch(model, criterion, next(owt_iter)['tokens'], owt_batch_size, fixed_demos)\n",
    "            tox_loss, owt_loss = infer_batch_with_owt(model, criterion, batch, next(owt_iter), batch_size, demos, access_toxic_pos=-1)\n",
    "            # print(f\"{tox_loss=}, {owt_loss=}\")\n",
    "            loss = -1 * (regularization_strength * penalty + alpha * tox_loss) + owt_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "            num_ablated_edges.append(ablated_edges)\n",
    "            for p in mask_params:\n",
    "                p.data.clamp_(0,1)\n",
    "        print(f\"{loss.item()=}, {ablated_edges=}\")\n",
    "        epochs_trained += 1\n",
    "        if epochs_trained % clamp_every == 0:\n",
    "            ablated_edges = 0\n",
    "            for p in mask_params:\n",
    "                p.data[p.data < threshold] = 0\n",
    "                p.data[p.data >= threshold] = 1\n",
    "                ablated_edges += p[p.data < 0.5].shape[0]\n",
    "        if epochs_trained % log_every == 0:\n",
    "            print(\"Epochs trained: \", epochs_trained)\n",
    "            print(f\"Loss: {loss.item():.4f}\")\n",
    "            print(f\"Total preserved: {total_preserving:.4f}\")\n",
    "            print(\"Edges ablated: \", ablated_edges)\n",
    "            print(\"Toxic loss: \", tox_loss.item())\n",
    "            print(\"OWT loss: \", owt_loss.item())\n",
    "            print(\"Penalty: \", penalty)\n",
    "            # if input('evaluate? (y)') == 'y':\n",
    "            #     evaluate_model(model, toxic_batches=1, owt_batches=1)\n",
    "            print(\"\\n\")\n",
    "            old_mask_params[epochs_trained] = duplicate_mask_params(mask_params)\n",
    "                \n",
    "        if epochs_trained > 50 and ablated_edges < edge_threshold:\n",
    "            break\n",
    "        prev_params = mask_params\n",
    "    epochs_left = int(input('continue training for this number of epochs: '))\n",
    "    log_every = int(input('set log frequency'))\n",
    "    edge_threshold = int(input('set edge threshold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/alternative_acdc_cb_subset_mask_params_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(old_mask_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model before and after circuit breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/ioi_sentences_test.pkl\", \"rb\") as f:\n",
    "    ioi_sentences_test = pickle.load(f)\n",
    "    # ioi_sentences_test = [t[2] for t in ioi_sentences_test]\n",
    "\n",
    "with open(\"data/eval_uniform.pkl\", \"rb\") as f:\n",
    "    uniform_samples = pickle.load(f)\n",
    "    uniform_sentences = [t[2] for t in uniform_samples]\n",
    "\n",
    "original_model = load_demo_gpt2(means=False)\n",
    "\n",
    "# with open(\"models/masked_gpt2_mean_ablation_v6.pkl\", \"rb\") as f:\n",
    "#     model.state_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on an ioi_sentence\n",
    "ioi_sentence = ioi_sentences_test[0]\n",
    "print(ioi_sentence)\n",
    "# ioi_tokens = tokenizer(ioi_sentence, return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "original_model.eval()\n",
    "original_model.to('cuda')\n",
    "def get_last_token(model, prompt, topk=5):\n",
    "    # generate last token\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').input_ids[:, :-1]\n",
    "\n",
    "    # generate one token, decode original_model(ioi_tokens[:, :-1])\n",
    "    model_outputs = model(tokens)[0]\n",
    "    model_outputs = model_outputs.squeeze(0)[-1]\n",
    "    probs = torch.nn.functional.softmax(model_outputs, dim=-1)\n",
    "\n",
    "    topk_outputs = torch.topk(model_outputs, topk)\n",
    "    topk_tokens = topk_outputs.indices\n",
    "    topk_probs = probs[topk_outputs.indices]\n",
    "    \n",
    "    # decode tokens\n",
    "    for i in range(topk):\n",
    "        print(f\"{tokenizer.decode(topk_tokens[i].unsqueeze(0))}, probability of {topk_probs[i]}\")\n",
    "    topk_tokens_decoded = tokenizer.batch_decode(topk_tokens)\n",
    "    return topk_tokens_decoded, topk_probs\n",
    "\n",
    "print(\"Before ablation\")\n",
    "_ = get_last_token(original_model, ioi_sentence)\n",
    "print()\n",
    "print()\n",
    "print(\"After ablation\")\n",
    "_ = get_last_token(model, ioi_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on uniform samples\n",
    "for idx in range(3):\n",
    "    print(uniform_sentences[idx])\n",
    "    print(\"Before ablation\")\n",
    "    _ = get_last_token(original_model, uniform_sentences[idx])\n",
    "    print()\n",
    "    print(\"After ablation\")\n",
    "    _ = get_last_token(model, uniform_sentences[idx])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize mask\n",
    "Create the computational graphs in edge attribution patching paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate which nodes will be in the graph\n",
    "connected_nodes = set()\n",
    "# add embed node at position\n",
    "# connected_nodes.add((-1, \"embed\"))\n",
    "n_heads = 12\n",
    "n_layers = 12\n",
    "\n",
    "# associate each node with a position\n",
    "all_possible_nodes = [(-1, \"embed\")]\n",
    "mask_dict = {}\n",
    "# empty tensor\n",
    "mask_dict[\"embed\"] = torch.zeros(size=(0,))\n",
    "for idx in range(len(mask_params)):\n",
    "    if \"attention\" in param_names[idx]:\n",
    "        layer = int(param_names[idx].split(\".\")[1])\n",
    "        for i in range(n_heads):\n",
    "            all_possible_nodes.append((layer, f\"a{layer}.{i}\"))\n",
    "            mask_dict[f\"a{layer}.{i}\"] = mask_params[idx][:,i].detach().cpu()\n",
    "    elif \"mlp\" in param_names[idx]:\n",
    "        layer = int(param_names[idx].split(\".\")[1])\n",
    "        all_possible_nodes.append((layer, f\"m{layer}\"))\n",
    "        mask_dict[f\"m{layer}\"] = mask_params[idx].detach().cpu()\n",
    "all_possible_nodes.append((n_heads, \"output\"))\n",
    "mask_dict[\"output\"] = mask_params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate where edges are based on the mask\n",
    "# Edge between node i and node j if mask_dict[i][all_possible_nodes.index(j)] == 0\n",
    "sufficient = True\n",
    "\n",
    "edges = []\n",
    "for i in range(len(all_possible_nodes)):\n",
    "    for j in range(len(all_possible_nodes)):\n",
    "        j_index = all_possible_nodes.index(all_possible_nodes[j])\n",
    "        if j_index < len(mask_dict[all_possible_nodes[i][1]]) and mask_dict[all_possible_nodes[i][1]][all_possible_nodes.index(all_possible_nodes[j])] == (1 if sufficient else 0):\n",
    "            edges.append((all_possible_nodes[i], all_possible_nodes[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aligned_graph(all_possible_nodes, edges):\n",
    "    G = pgv.AGraph(strict=False, directed=True)\n",
    "\n",
    "    # Find the maximum layer number for adjusting the graph\n",
    "    max_layer = max(layer for layer, _ in all_possible_nodes if isinstance(layer, int))\n",
    "    nodes_with_edges = set([node for edge in edges for node in edge])\n",
    "    print(nodes_with_edges)\n",
    "    # Add nodes and edges to the graph\n",
    "    # for node in all_possible_nodes:\n",
    "    #     if node in [edge[0] for edge in edges] or node in [edge[1] for edge in edges]:\n",
    "    #         G.add_node(node[1], layer=str(max_layer - node[0]))\n",
    "\n",
    "    for edge in edges:\n",
    "        G.add_edge(edge[1][1], edge[0][1])\n",
    "\n",
    "    # Create subgraphs to ensure nodes of the same layer have the same rank\n",
    "    for layer in range(max_layer, -2, -1):\n",
    "        with G.subgraph(name=f'cluster_{layer}') as s:\n",
    "            s.graph_attr['rank'] = 'same'\n",
    "            for node in nodes_with_edges:\n",
    "                if node[0] == layer:\n",
    "                    s.add_node(node[1])\n",
    "\n",
    "    # Apply layout and render the graph\n",
    "    G.layout(prog='dot')\n",
    "    G.draw('aligned_graph.png')\n",
    "    return Image('aligned_graph.png')\n",
    "\n",
    "# Call the function with your nodes and edges\n",
    "flipped_graph_image = create_aligned_graph(all_possible_nodes, edges)\n",
    "\n",
    "# To display the graph in Jupyter Notebook\n",
    "flipped_graph_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlrn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
