{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train mask over IOI edges and analyze mask vs known circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from models import load_gpt2_weights, load_demo_gpt2, tokenizer\n",
    "from data import retrieve_toxic_data, retrieve_owt_data, retrieve_toxic_data_low_loss, retrieve_toxic_filtered_data, FILTER_DEMO_LEN, CONTEXT_LENGTH\n",
    "from inference import infer_batch_with_owt, infer_batch, prepare_fixed_demo, criterion\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import pickle\n",
    "import datasets\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import cycle\n",
    "# from eval import evaluate_model\n",
    "from data import batch_text_to_tokens\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mask into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_ioi = True\n",
    "\n",
    "if means_ioi:\n",
    "    with open(\"data/gpt2_ioi_abc_means.pkl\", \"rb\") as f:\n",
    "        means = pickle.load(f)[0]\n",
    "else:\n",
    "    with open(\"data/gpt2_means.pkl\", \"rb\") as f:\n",
    "        means = pickle.load(f)[0]\n",
    "\n",
    "model = load_demo_gpt2(means=means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/alternative_necessary_masks_params_dict_lambda=1_means_ioi=True.pkl\", \"rb\") as f:\n",
    "    necessary_masks_dict = pickle.load(f)\n",
    "with open(\"models/alternative_sufficient_masks_params_dict_lambda=1_means_ioi=True.pkl\", \"rb\") as f:\n",
    "    sufficient_masks_dict = pickle.load(f)\n",
    "with open(\"models/params_dict_lambda=1.pkl\", \"rb\") as f:\n",
    "    mask_params_dict = pickle.load(f)\n",
    "with open(\"models/acdcpp_mask_params.pkl\", \"rb\") as f:\n",
    "    acdcpp_mask_params = pickle.load(f)\n",
    "\n",
    "final_masks = {\"necessary\": necessary_masks_dict[200], \"sufficient\": sufficient_masks_dict[200], \"acdcpp\": acdcpp_mask_params, \"circuit_breaking\": mask_params_dict[200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask_into_model(model, mask):\n",
    "    # load in place\n",
    "    mask_idx = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            param.data = mask[mask_idx].to(param.device)\n",
    "            mask_idx += 1\n",
    "\n",
    "def reset_mask(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            param.data = torch.ones_like(param.data).to(param.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model before and after circuit breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/ioi_prompts_test.pkl\", \"rb\") as f:\n",
    "    ioi_prompts_test = pickle.load(f)\n",
    "    # ioi_sentences_test = [t[2] for t in ioi_sentences_test]\n",
    "\n",
    "with open(\"data/eval_uniform.pkl\", \"rb\") as f:\n",
    "    uniform_samples = pickle.load(f)\n",
    "    uniform_sentences = [t[2] for t in uniform_samples]\n",
    "\n",
    "with open(\"models/masked_gpt2_mean_ablation_v6.pkl\", \"rb\") as f:\n",
    "    model.state_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PLACE]': 'restaurant', '[OBJECT]': 'snack', 'text': 'While Alicia and Joshua were commuting to the restaurant, Joshua gave a snack to Alicia', 'IO': 'Alicia', 'S': 'Joshua', 'TEMPLATE_IDX': 24, 'C': 'Laura'}\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an ioi_sentence\n",
    "ioi_prompt = ioi_prompts_test[0]\n",
    "print(ioi_prompt)\n",
    "\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "def get_last_token(model, prompt, topk=5, sentence=False):\n",
    "    # generate last token\n",
    "    if not sentence:\n",
    "        prompt_sentence = prompt['text']\n",
    "    else:\n",
    "        prompt_sentence = prompt\n",
    "\n",
    "    tokens = tokenizer(prompt_sentence, return_tensors='pt').input_ids[:, :-1]\n",
    "\n",
    "    # generate one token, decode original_model(ioi_tokens[:, :-1])\n",
    "    model_outputs = model(tokens)[0]\n",
    "    model_outputs = model_outputs.squeeze(0)[-1]\n",
    "    probs = torch.nn.functional.softmax(model_outputs, dim=-1)\n",
    "\n",
    "    topk_outputs = torch.topk(model_outputs, topk)\n",
    "    topk_tokens = topk_outputs.indices\n",
    "    topk_probs = probs[topk_outputs.indices]\n",
    "    \n",
    "    topk_tokens_decoded = tokenizer.batch_decode(topk_tokens)\n",
    "    \n",
    "    if not sentence:\n",
    "        # Get logit diff by finding difference between logit of \n",
    "        io_token = tokenizer(\" \" + prompt['IO'], return_tensors='pt').input_ids[:, -1]\n",
    "        s_token = tokenizer(\" \" + prompt['S'], return_tensors='pt').input_ids[:, -1]\n",
    "        logit_diff = model_outputs[io_token][0] - model_outputs[s_token][0]\n",
    "        return topk_tokens_decoded, topk_probs, logit_diff\n",
    "    return topk_tokens_decoded, topk_probs\n",
    "\n",
    "def get_ioi_score(model, num_samples):\n",
    "    ave_logit_diffs = []\n",
    "    for idx in range(num_samples):\n",
    "        prompt = ioi_prompts_test[idx]\n",
    "        ave_logit_diffs.append(get_last_token(model, prompt)[2])\n",
    "    return sum(ave_logit_diffs) / len(ave_logit_diffs)\n",
    "\n",
    "# get OWT loss\n",
    "def get_owt_loss(model, num_samples):\n",
    "    owt_losses = []\n",
    "    for idx in range(num_samples):\n",
    "        prompt = uniform_sentences[idx]\n",
    "        owt_losses.append(infer_batch_with_owt(model, prompt['text'], prompt['IO'], prompt['S']))\n",
    "    return sum(owt_losses) / len(owt_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_mask(mask, keep_output=True):\n",
    "    new_mask = []\n",
    "    for idx, m in enumerate(mask):\n",
    "        if idx == 0 and keep_output:\n",
    "            new_mask.append(torch.ones_like(m))\n",
    "        else:\n",
    "            new_mask.append(1 - m)\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average logit diff with no edges masked:  tensor(4.1287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Average logit diff with necessary edges masked: 0.013599695637822151\n",
      "Average logit diff with sufficient edges masked: -2.8097500801086426\n",
      "Average logit diff post circuit-breaking: 0.3835521340370178\n",
      "Average logit diff post masking ACDC++: 0.004391784779727459\n"
     ]
    }
   ],
   "source": [
    "reset_mask(model)\n",
    "print(\"Average logit diff with no edges masked: \", get_ioi_score(model, 20))\n",
    "\n",
    "load_mask_into_model(model, necessary_masks_dict[200])\n",
    "print(f\"Average logit diff with necessary edges masked: {get_ioi_score(model, 50)}\")\n",
    "\n",
    "load_mask_into_model(model, sufficient_masks_dict[200])\n",
    "print(f\"Average logit diff with sufficient edges masked: {get_ioi_score(model, 50)}\")\n",
    "\n",
    "load_mask_into_model(model, mask_params_dict[200])\n",
    "print(f\"Average logit diff post circuit-breaking: {get_ioi_score(model, 50)}\")\n",
    "\n",
    "load_mask_into_model(model, acdcpp_mask_params)\n",
    "print(f\"Average logit diff post masking ACDC++: {get_ioi_score(model, 50)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverted Masks\n",
      "Average logit diff with no edges masked:  tensor(4.1287, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAverage logit diff with no edges masked: \u001b[39m\u001b[39m\"\u001b[39m, get_ioi_score(model, \u001b[39m20\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m load_mask_into_model(model, invert_mask(necessary_masks_dict[\u001b[39m200\u001b[39m]))\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAverage logit diff with necessary edges masked: \u001b[39m\u001b[39m{\u001b[39;00mget_ioi_score(model,\u001b[39m \u001b[39m\u001b[39m100\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m load_mask_into_model(model, invert_mask(sufficient_masks_dict[\u001b[39m200\u001b[39m]))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAverage logit diff with sufficient edges masked: \u001b[39m\u001b[39m{\u001b[39;00mget_ioi_score(model,\u001b[39m \u001b[39m\u001b[39m100\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_samples):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     prompt \u001b[39m=\u001b[39m ioi_prompts_test[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     ave_logit_diffs\u001b[39m.\u001b[39mappend(get_last_token(model, prompt)[\u001b[39m2\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(ave_logit_diffs) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(ave_logit_diffs)\n",
      "\u001b[1;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m tokens \u001b[39m=\u001b[39m tokenizer(prompt_sentence, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39minput_ids[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# generate one token, decode original_model(ioi_tokens[:, :-1])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m model_outputs \u001b[39m=\u001b[39m model(tokens)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m model_outputs \u001b[39m=\u001b[39m model_outputs\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_masks.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m probs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(model_outputs, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/transformer.py:331\u001b[0m, in \u001b[0;36mDemoTransformer.forward\u001b[0;34m(self, tokens, return_states)\u001b[0m\n\u001b[1;32m    327\u001b[0m residual \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(residual, \u001b[39m\"\u001b[39m\u001b[39mbatch position d_model -> batch position 1 d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    329\u001b[0m \u001b[39mfor\u001b[39;00m i, block \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks):\n\u001b[1;32m    330\u001b[0m     \u001b[39m# print(i)\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     residual \u001b[39m=\u001b[39m block(residual, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeans)\n\u001b[1;32m    332\u001b[0m     \u001b[39m# if hasattr(self,\"saved_states\"):\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[39m#     self.saved_states = torch.cat((self.saved_states, block.saved_output.unsqueeze(0)), dim=0)\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[39m# else:\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[39m#     self.saved_states = block.saved_output.unsqueeze(0)\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m return_states:\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/transformer.py:255\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, means)\u001b[0m\n\u001b[1;32m    251\u001b[0m normalized_resid_pre \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln1(masked_residuals, parallel\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    252\u001b[0m \u001b[39m# print(normalized_resid_pre[:,:,0])\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39m# print(torch.allclose(normalized_resid_pre[:,:,torch.randperm(normalized_resid_pre.shape[2])],normalized_resid_pre))\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m attn_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(normalized_resid_pre)\n\u001b[1;32m    257\u001b[0m \u001b[39m# self.saved_output = attn_out\u001b[39;00m\n\u001b[1;32m    259\u001b[0m residual \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((resid_pre, attn_out), dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/transformer.py:155\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, normalized_resid_pre)\u001b[0m\n\u001b[1;32m    153\u001b[0m attn_scores \u001b[39m=\u001b[39m einsum(\u001b[39m\"\u001b[39m\u001b[39mbatch query_pos n_heads d_head, batch key_pos n_heads d_head -> batch n_heads query_pos key_pos\u001b[39m\u001b[39m\"\u001b[39m, q, k)\n\u001b[1;32m    154\u001b[0m attn_scores \u001b[39m=\u001b[39m attn_scores \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39md_head)\n\u001b[0;32m--> 155\u001b[0m attn_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_causal_mask(attn_scores)\n\u001b[1;32m    157\u001b[0m pattern \u001b[39m=\u001b[39m attn_scores\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# [batch, n_head, query_pos, key_pos]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m v \u001b[39m=\u001b[39m einsum(\u001b[39m\"\u001b[39m\u001b[39mbatch key_pos n_heads d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\u001b[39m\u001b[39m\"\u001b[39m, normalized_resid_pre, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_V) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_V\n",
      "File \u001b[0;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/transformer.py:168\u001b[0m, in \u001b[0;36mAttention.apply_causal_mask\u001b[0;34m(self, attn_scores)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_causal_mask\u001b[39m(\u001b[39mself\u001b[39m, attn_scores):\n\u001b[1;32m    166\u001b[0m     \u001b[39m# attn_scores: [batch, n_heads, query_pos, key_pos]\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtriu(torch\u001b[39m.\u001b[39mones(attn_scores\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m), attn_scores\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), device\u001b[39m=\u001b[39mattn_scores\u001b[39m.\u001b[39mdevice), diagonal\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mbool()\n\u001b[0;32m--> 168\u001b[0m     attn_scores\u001b[39m.\u001b[39;49mmasked_fill_(mask, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mIGNORE)\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_scores\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Inverted Masks\")\n",
    "reset_mask(model)\n",
    "print(\"Average logit diff with no edges masked: \", get_ioi_score(model, 20))\n",
    "\n",
    "load_mask_into_model(model, invert_mask(necessary_masks_dict[200]))\n",
    "print(f\"Average logit diff with necessary edges masked: {get_ioi_score(model, 100)}\")\n",
    "\n",
    "load_mask_into_model(model, invert_mask(sufficient_masks_dict[200]))\n",
    "print(f\"Average logit diff with sufficient edges masked: {get_ioi_score(model, 100)}\")\n",
    "\n",
    "load_mask_into_model(model, invert_mask(mask_params_dict[200]))\n",
    "print(f\"Average logit diff post circuit-breaking: {get_ioi_score(model, 100)}\")\n",
    "\n",
    "load_mask_into_model(model, invert_mask(acdcpp_mask_params))\n",
    "print(f\"Average logit diff post masking ACDC++: {get_ioi_score(model, 100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Check Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mover_heads = ['a10.0', 'a9.9', 'a9.6']\n",
    "negative_heads = ['a10.7', 'a11.10']\n",
    "s2_inhibition_heads = ['a8.10', 'a7.9', 'a8.6', 'a7.3']\n",
    "induction_heads = ['a5.5', 'a6.9', 'a5.9', 'a5.8']\n",
    "duplicate_token_heads = ['a0.1', 'a0.10', 'a3.0']\n",
    "previous_token_heads = ['a4.11', 'a2.2', 'a2.9']\n",
    "backup_name_mover_heads = ['a11.2', 'a10.2', 'a10.6', 'a10.1', 'a10.10', 'a9.7', 'a11.9', 'a11.3']\n",
    "\n",
    "circuit_dict = {}\n",
    "\n",
    "for head in name_mover_heads:\n",
    "    circuit_dict[head] = 'name_mover'\n",
    "\n",
    "for head in negative_heads:\n",
    "    circuit_dict[head] = 'negative'\n",
    "\n",
    "for head in s2_inhibition_heads:\n",
    "    circuit_dict[head] = 's2_inhibition'\n",
    "\n",
    "for head in induction_heads:\n",
    "    circuit_dict[head] = 'induction'\n",
    "\n",
    "for head in duplicate_token_heads:\n",
    "    circuit_dict[head] = 'duplicate_token'\n",
    "\n",
    "for head in previous_token_heads:\n",
    "    circuit_dict[head] = 'previous_token'\n",
    "\n",
    "for head in backup_name_mover_heads:\n",
    "    circuit_dict[head] = 'backup_name_mover'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of relevant edges: 63, number of circuit edges: 0\n"
     ]
    }
   ],
   "source": [
    "def check_relevant_edges(mask_edges, circuit_nodes=circuit_dict):\n",
    "    # edges where one of the nodes is in the circuit\n",
    "    relevant_edges = []\n",
    "\n",
    "    # edges where both nodes are in the circuit\n",
    "    circuit_edges = []\n",
    "    \n",
    "    for edge in mask_edges:\n",
    "        if edge[0][1] in circuit_nodes or edge[1][1] in circuit_nodes:\n",
    "            relevant_edges.append(edge)\n",
    "        if edge[0][1] in circuit_nodes and edge[1][1] in circuit_nodes:\n",
    "            circuit_edges.append(edge)\n",
    "    return relevant_edges, circuit_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of relevant edges: 63, number of circuit edges: 0\n",
      "number of relevant edges: 158, number of circuit edges: 62\n"
     ]
    }
   ],
   "source": [
    "from mask_utils import get_nodes_and_edges\n",
    "_, _, sufficient_edges, _ = get_nodes_and_edges(necessary_masks_dict[200])\n",
    "relevant_edges, circuit_edges = check_relevant_edges(sufficient_edges)\n",
    "print(f\"number of relevant edges: {len(relevant_edges)}, number of circuit edges: {len(circuit_edges)}\")\n",
    "\n",
    "_, _, acdcpp_edges, _ = get_nodes_and_edges(acdcpp_mask_params)\n",
    "relevant_edges, circuit_edges = check_relevant_edges(acdcpp_edges)\n",
    "print(f\"number of relevant edges: {len(relevant_edges)}, number of circuit edges: {len(circuit_edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize mask\n",
    "Create the computational graphs in edge attribution patching paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mask and calculate what edges are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_and_edges(mask_params, edge_0=True):\n",
    "    \"\"\"\n",
    "    If edge_0 is True, then edges are between nodes with mask value 0. Else, edges are between nodes with mask value 1.\n",
    "    \"\"\"\n",
    "    # calculate which nodes will be in the graph\n",
    "    connected_nodes = set()\n",
    "    # add embed node at position\n",
    "    # connected_nodes.add((-1, \"embed\"))\n",
    "    n_heads = 12\n",
    "    n_layers = 12\n",
    "\n",
    "    # associate each node with a position\n",
    "    all_possible_nodes = [(-1, \"embed\")]\n",
    "    mask_dict = {}\n",
    "    # empty tensor\n",
    "    mask_dict[\"embed\"] = torch.zeros(size=(0,))\n",
    "    for idx in range(len(mask_params)):\n",
    "        if \"attention\" in param_names[idx]:\n",
    "            layer = int(param_names[idx].split(\".\")[1])\n",
    "            for i in range(n_heads):\n",
    "                all_possible_nodes.append((layer, f\"a{layer}.{i}\"))\n",
    "                mask_dict[f\"a{layer}.{i}\"] = mask_params[idx][:,i].detach().cpu()\n",
    "        elif \"mlp\" in param_names[idx]:\n",
    "            layer = int(param_names[idx].split(\".\")[1])\n",
    "            all_possible_nodes.append((layer, f\"m{layer}\"))\n",
    "            mask_dict[f\"m{layer}\"] = mask_params[idx].detach().cpu()\n",
    "    all_possible_nodes.append((n_heads, \"output\"))\n",
    "    mask_dict[\"output\"] = mask_params[-1]\n",
    "\n",
    "    # Calculate where edges are based on the mask\n",
    "    # Edge between node i and node j if mask_dict[i][all_possible_nodes.index(j)] == 0\n",
    "    edges = set()\n",
    "    for i in range(len(all_possible_nodes)):\n",
    "        for j in range(len(all_possible_nodes)):\n",
    "            j_index = all_possible_nodes.index(all_possible_nodes[j])\n",
    "            if j_index < len(mask_dict[all_possible_nodes[i][1]]) and mask_dict[all_possible_nodes[i][1]][all_possible_nodes.index(all_possible_nodes[j])] == (0 if edge_0 else 1):\n",
    "                edges.add((all_possible_nodes[i], all_possible_nodes[j]))\n",
    "    \n",
    "    nodes_with_edges = set([node for edge in edges for node in edge])\n",
    "\n",
    "    return all_possible_nodes, nodes_with_edges, edges, mask_dict\n",
    "all_possible_nodes, nodes_with_edges, edges, mask_dict = get_nodes_and_edges(mask_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze ACDC and Compare\n",
    "I separately used ACDC++ (EAP from \"Attribution Patching Outperforms Automated Circuit Discovery\" paper) to get the known circuit edges. I want to compare my various learned masks (from different losses) to the known circuit edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/acdcpp_edges.pkl\", \"rb\") as f:\n",
    "    acdcpp_edges_long = pickle.load(f)\n",
    "acdcpp_edges_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acdcpp edges are in format 'blocks.1.attn.hook_result[:, :, 10]blocks.0.hook_mlp_in[:]', convert to format of ((1, 'a1.10'), (0, 'm0'))\n",
    "\n",
    "def get_node_name(node_name, show_full_index=False):\n",
    "    \"\"\"Node name for use in pretty graphs\"\"\"\n",
    "\n",
    "    def get_index(node_name_long):\n",
    "        # Get the index by looking for number in brackets\n",
    "        # e.g. blocks.1.attn.hook_result[:, :, 10] -> 10\n",
    "        index = node_name_long.split(\"[\")[-1].split(\"]\")[0]\n",
    "        index = index.split(\", \")[-1]\n",
    "        return int(index)\n",
    "\n",
    "    if not show_full_index:\n",
    "        name = \"\"\n",
    "        qkv_substrings = [f\"hook_{letter}\" for letter in [\"q\", \"k\", \"v\"]]\n",
    "        qkv_input_substrings = [f\"hook_{letter}_input\" for letter in [\"q\", \"k\", \"v\"]]\n",
    "\n",
    "        # Handle embedz\n",
    "        if \"resid_pre\" in node_name:\n",
    "            assert \"0\" in node_name and not any([str(i) in node_name for i in range(1, 10)])\n",
    "            name += \"embed\"\n",
    "            layer = -1\n",
    "            # if len(node.index.hashable_tuple) > 2:\n",
    "            #     name += f\"_[{node.index.hashable_tuple[2]}]\"\n",
    "            # return name\n",
    "\n",
    "        elif \"embed\" in node_name:\n",
    "            name = \"pos_embeds\" if \"pos\" in node_name else \"token_embeds\"\n",
    "            layer = -1\n",
    "\n",
    "        # Handle q_input and hook_q etc\n",
    "        elif any([node_name.endswith(qkv_input_substring) for qkv_input_substring in qkv_input_substrings]):\n",
    "            relevant_letter = None\n",
    "            for letter, qkv_substring in zip([\"q\", \"k\", \"v\"], qkv_substrings):\n",
    "                if qkv_substring in node_name:\n",
    "                    assert relevant_letter is None\n",
    "                    relevant_letter = letter\n",
    "            name += \"a\" + node_name.split(\".\")[1] + \".\" + str(get_index(node_name)) + \"_\" + relevant_letter\n",
    "            layer = int(node_name.split(\".\")[1])\n",
    "\n",
    "        # Handle attention hook_result\n",
    "        elif \"hook_result\" in node_name or any([qkv_substring in node_name for qkv_substring in qkv_substrings]):\n",
    "            name = \"a\" + node_name.split(\".\")[1] + \".\" + str(get_index(node_name))\n",
    "            layer = int(node_name.split(\".\")[1])\n",
    "\n",
    "        # Handle MLPs\n",
    "        elif node_name.endswith(\"resid_mid\"):\n",
    "            raise ValueError(\"We removed resid_mid annotations. Call these mlp_in now.\")\n",
    "        elif \"mlp\" in node_name:\n",
    "            name = \"m\" + node_name.split(\".\")[1]\n",
    "            layer = int(node_name.split(\".\")[1])\n",
    "\n",
    "        # Handle resid_post\n",
    "        elif \"resid_post\" in node_name:\n",
    "            name += \"resid_post\"\n",
    "            layer = 12\n",
    "\n",
    "        # elif \"mlp\" in node_name:\n",
    "        #     name += \"m\" + node_name.split(\".\")[1]\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized node name {node_name}\")\n",
    "\n",
    "    else:\n",
    "        name = node_name\n",
    "        # name = node_name + str(node.index.graphviz_index(use_actual_colon=True))\n",
    "\n",
    "    # get layer by looking for number before first dot\n",
    "    \n",
    "\n",
    "    return layer, name\n",
    "\n",
    "acdcpp_edges = set()\n",
    "for edge in acdcpp_edges_long[0][0.08]:\n",
    "    # split the edge into two nodes, e.g. blocks.1.attn.hook_result[:, :, 10]blocks.0.hook_mlp_in[:] into blocks.1.attn.hook_result[:, :, 10] and blocks.0.hook_mlp_in[:]\n",
    "    node_1 = get_node_name(edge.split(\"]\")[0]+\"]\", show_full_index=False)\n",
    "    node_2 = get_node_name(edge.split(\"]\")[1]+\"]\", show_full_index=False)\n",
    "    acdcpp_edges.add((node_1, node_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze overlaps between different edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/alternative_necessary_masks_params_dict_lambda=1.pkl\", \"rb\") as f:\n",
    "    alternative_necessary_mask_params = pickle.load(f)\n",
    "    alternative_necessary_mask_params = alternative_necessary_mask_params[200]\n",
    "with open(\"models/alternative_sufficient_masks_params_dict_lambda=1.pkl\", \"rb\") as f:\n",
    "    alternative_sufficient_mask_params = pickle.load(f)\n",
    "    alternative_sufficient_mask_params = alternative_sufficient_mask_params[200]\n",
    "_, _, alternative_necessary_edges, _ = get_nodes_and_edges(alternative_necessary_mask_params)\n",
    "_, _, alternative_sufficient_edges, _ = get_nodes_and_edges(alternative_sufficient_mask_params, edge_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nodes_and_edges(alternative_sufficient_mask_params, edge_0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(edges)=}, {len(acdcpp_edges)=}, {len(edges.intersection(acdcpp_edges))=}\")\n",
    "print(edges.intersection(acdcpp_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overlaps between all edges (regular edges, necessary, sufficient, acdcpp) (make a table with tabulate)\n",
    "edges_dict = {\"circuit_breaking\":edges, \"ioi_necessary\":alternative_necessary_edges, \"ioi_sufficient\":alternative_sufficient_edges, \"acdcpp\":acdcpp_edges}\n",
    "for edge_type in edges_dict:\n",
    "    for second_edge_type in edges_dict:\n",
    "        print(f\"{edge_type} and {second_edge_type}: {len(edges_dict[edge_type].intersection(edges_dict[second_edge_type]))} edges in common\")#, {edges_dict[edge_type].intersection(edges_dict[second_edge_type])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aligned_graph(all_possible_nodes, edges):\n",
    "    G = pgv.AGraph(strict=False, directed=True)\n",
    "\n",
    "    # Find the maximum layer number for adjusting the graph\n",
    "    max_layer = max(layer for layer, _ in all_possible_nodes if isinstance(layer, int))\n",
    "    nodes_with_edges = set([node for edge in edges for node in edge])\n",
    "\n",
    "    # Add nodes and edges to the graph\n",
    "    for node in all_possible_nodes:\n",
    "        if node in [edge[0] for edge in edges] or node in [edge[1] for edge in edges]:\n",
    "            G.add_node(node[1], layer=str(max_layer - node[0]))\n",
    "\n",
    "    for edge in edges:\n",
    "        G.add_edge(edge[1][1], edge[0][1])\n",
    "\n",
    "    # Create subgraphs to ensure nodes of the same layer have the same rank\n",
    "    for layer in range(max_layer, -2, -1):\n",
    "        with G.subgraph(name=f'cluster_{layer}') as s:\n",
    "            s.graph_attr['rank'] = 'same'\n",
    "            for node in nodes_with_edges:\n",
    "                if node[0] == layer:\n",
    "                    s.add_node(node[1])\n",
    "\n",
    "    # Apply layout and render the graph\n",
    "    G.layout(prog='dot')\n",
    "    G.draw('aligned_graph.png')\n",
    "    return Image('aligned_graph.png')\n",
    "\n",
    "# Call the function with your nodes and edges\n",
    "flipped_graph_image = create_aligned_graph(all_possible_nodes, edges)\n",
    "\n",
    "# To display the graph in Jupyter Notebook\n",
    "flipped_graph_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersecting edges graph\n",
    "for edge_type in edges_dict:\n",
    "    for second_edge_type in edges_dict:\n",
    "        if edge_type == second_edge_type:\n",
    "            continue\n",
    "        # make a graph with just the intersecting edges, title it with the two edge types\n",
    "        print(f\"Intersection between {edge_type} and {second_edge_type}: {len(edges_dict[edge_type].intersection(edges_dict[second_edge_type]))} edges in common, {edges_dict[edge_type].intersection(edges_dict[second_edge_type])}\")\n",
    "        \n",
    "        intersecting_edges_graph = create_aligned_graph(all_possible_nodes, edges_dict[edge_type].intersection(edges_dict[second_edge_type]))\n",
    "        display(intersecting_edges_graph)\n",
    "        # intersecting_edges_graph.render(f\"intersecting_edges_graph_{edge_type}_{second_edge_type}\", format=\"png\", cleanup=True)\n",
    "# intersecting_edges_graph = create_aligned_graph(all_possible_nodes, edges.intersection(acdcpp_edges))\n",
    "# intersecting_edges_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "from pathlib import Path\n",
    "from IPython.display import Image\n",
    "\n",
    "def show(nodes, edges, fname=None):\n",
    "    g = pgv.AGraph(strict=True, directed=True)\n",
    "    g.graph_attr.update(ranksep='0.1', nodesep='0.1', compound=True)\n",
    "    g.node_attr.update(fixedsize='true', width='1.5', height='.5')\n",
    "    \n",
    "    layer_to_subgraph = {}\n",
    "\n",
    "    # Create a subgraph for each layer\n",
    "    for node in nodes:\n",
    "        layer = node[0]\n",
    "        if layer not in layer_to_subgraph:\n",
    "            # Each layer has its own subgraph with 'rank=same' to ensure they are on the same level\n",
    "            layer_to_subgraph[layer] = g.add_subgraph(name=f'cluster_{layer}', rank='same')\n",
    "            \n",
    "        # Here you add the node to the appropriate subgraph\n",
    "        layer_to_subgraph[layer].add_node(node, label=str(node[1]))\n",
    "\n",
    "    # Now, add the edges to the graph\n",
    "    for edge in edges:\n",
    "        g.add_edge(edge[0], edge[1])\n",
    "    \n",
    "    # If a filename is provided, write the file and optionally render to an image\n",
    "    if fname:\n",
    "        fpath = Path(fname)\n",
    "        base_fname = fpath.stem\n",
    "        base_path = fpath.parent\n",
    "        base_path.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        # Write the dot file\n",
    "        g.write(path=base_path / f\"{base_fname}.gv\")\n",
    "        \n",
    "        # Render to an image\n",
    "        g.layout(prog='dot')\n",
    "        g.draw(path=base_path / f\"{base_fname}.png\")\n",
    "        \n",
    "    return g\n",
    "\n",
    "\n",
    "g = show(nodes_with_edges, edges, fname=\"graph.gv\")\n",
    "Image(g.draw(format='png', prog='dot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlrn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
