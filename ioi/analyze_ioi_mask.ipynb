{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train mask over IOI edges and analyze mask vs known circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from models import load_gpt2_weights, load_demo_gpt2, tokenizer\n",
    "from data import retrieve_toxic_data, retrieve_owt_data, retrieve_toxic_data_low_loss, retrieve_toxic_filtered_data, FILTER_DEMO_LEN, CONTEXT_LENGTH\n",
    "from inference import infer_batch_with_owt, infer_batch, prepare_fixed_demo, criterion\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import pickle\n",
    "import datasets\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import cycle\n",
    "from eval import evaluate_model\n",
    "from data import batch_text_to_tokens\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_batch_size = 1 # so that we can just access the last sequence position without worrying about padding\n",
    "owt_batch_size = 5\n",
    "context_length = CONTEXT_LENGTH\n",
    "\n",
    "toxic_data_loader = retrieve_toxic_data(toxic_batch_size, context_length, tokenizer, tokenize=False, num_points=None)\n",
    "# toxic_data_loader = retrieve_toxic_filtered_data(toxic_batch_size)\n",
    "owt_data_loader = retrieve_owt_data(owt_batch_size)\n",
    "\n",
    "with open(\"data/gpt2_means.pkl\", \"rb\") as f:\n",
    "    means = pickle.load(f)[0][0]\n",
    "\n",
    "model = load_demo_gpt2(means=False)\n",
    "epochs_left = 100\n",
    "log_every = 10\n",
    "lr = .05 # free\n",
    "weight_decay = 0\n",
    "clamp_every = 50 # 5 # free\n",
    "threshold = 0.5\n",
    "epochs_trained = 0\n",
    "\n",
    "mask_params = []\n",
    "param_names = []\n",
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        param_names.append(name)\n",
    "        mask_params.append(p)\n",
    "optimizer = AdamW(mask_params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "losses = []\n",
    "num_ablated_edges = []\n",
    "alpha = 0.2 # free\n",
    "batch_size = toxic_batch_size + owt_batch_size\n",
    "demos = prepare_fixed_demo(tokenizer, batch_size, demo=\"\")\n",
    "owt_iter = cycle(owt_data_loader)\n",
    "edge_threshold = 100\n",
    "max_steps_per_epoch = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train params of mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17803/2201622741.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for e in tqdm(range(epochs_left)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779214cbd32e43d1bcc31875345da8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=-16.595102310180664, ablated_edges=3121\n",
      "loss.item()=-18.51873779296875, ablated_edges=4050\n",
      "loss.item()=-20.140392303466797, ablated_edges=4569\n",
      "loss.item()=-18.041257858276367, ablated_edges=4840\n",
      "loss.item()=-19.385272979736328, ablated_edges=5084\n",
      "loss.item()=-20.180282592773438, ablated_edges=5232\n",
      "loss.item()=-18.748977661132812, ablated_edges=5328\n",
      "loss.item()=-21.25680160522461, ablated_edges=5425\n",
      "loss.item()=-20.69216537475586, ablated_edges=5475\n",
      "loss.item()=-19.64101791381836, ablated_edges=5607\n",
      "Epochs trained:  10\n",
      "Loss: -19.6410\n",
      "Total preserved: 5981.6421\n",
      "Edges ablated:  5607\n",
      "Toxic loss:  119.28236389160156\n",
      "OWT loss:  4.215456962585449\n",
      "Penalty:  0\n",
      "\n",
      "\n",
      "loss.item()=-21.122892379760742, ablated_edges=5547\n",
      "loss.item()=-19.804641723632812, ablated_edges=5547\n",
      "loss.item()=-18.535991668701172, ablated_edges=5555\n",
      "loss.item()=-21.581907272338867, ablated_edges=5582\n",
      "loss.item()=-18.273487091064453, ablated_edges=5580\n",
      "loss.item()=-21.503908157348633, ablated_edges=5617\n",
      "loss.item()=-16.538253784179688, ablated_edges=5737\n",
      "loss.item()=-19.425701141357422, ablated_edges=5674\n",
      "loss.item()=-19.44955825805664, ablated_edges=5632\n",
      "loss.item()=-20.29948616027832, ablated_edges=5669\n",
      "Epochs trained:  20\n",
      "Loss: -20.2995\n",
      "Total preserved: 5893.4316\n",
      "Edges ablated:  5669\n",
      "Toxic loss:  122.67687225341797\n",
      "OWT loss:  4.235889911651611\n",
      "Penalty:  0\n",
      "\n",
      "\n",
      "loss.item()=-19.04178237915039, ablated_edges=5649\n",
      "loss.item()=-22.5939884185791, ablated_edges=5311\n",
      "loss.item()=-22.036577224731445, ablated_edges=4740\n",
      "loss.item()=-22.148412704467773, ablated_edges=4057\n",
      "loss.item()=-24.129608154296875, ablated_edges=3537\n",
      "loss.item()=-23.173046112060547, ablated_edges=3147\n",
      "loss.item()=-25.527616500854492, ablated_edges=2866\n",
      "loss.item()=-27.84830665588379, ablated_edges=2634\n",
      "loss.item()=-27.58399772644043, ablated_edges=2314\n",
      "loss.item()=-26.455623626708984, ablated_edges=2157\n",
      "Epochs trained:  30\n",
      "Loss: -26.4556\n",
      "Total preserved: 9241.9434\n",
      "Edges ablated:  2157\n",
      "Toxic loss:  110.68555450439453\n",
      "OWT loss:  3.999236822128296\n",
      "Penalty:  tensor(8.3177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-28.011476516723633, ablated_edges=2012\n",
      "loss.item()=-31.836509704589844, ablated_edges=1862\n",
      "loss.item()=-29.743303298950195, ablated_edges=1885\n",
      "loss.item()=-33.40204620361328, ablated_edges=1678\n",
      "loss.item()=-34.048824310302734, ablated_edges=1581\n",
      "loss.item()=-34.868995666503906, ablated_edges=1521\n",
      "loss.item()=-35.731422424316406, ablated_edges=1443\n",
      "loss.item()=-35.95623779296875, ablated_edges=1389\n",
      "loss.item()=-37.98210525512695, ablated_edges=1354\n",
      "loss.item()=-38.69461441040039, ablated_edges=1319\n",
      "Epochs trained:  40\n",
      "Loss: -38.6946\n",
      "Total preserved: 10123.5752\n",
      "Edges ablated:  1319\n",
      "Toxic loss:  118.71926879882812\n",
      "OWT loss:  4.2840375900268555\n",
      "Penalty:  tensor(19.2348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-37.62855911254883, ablated_edges=1217\n",
      "loss.item()=-42.467411041259766, ablated_edges=1178\n",
      "loss.item()=-42.18898010253906, ablated_edges=1141\n",
      "loss.item()=-43.84868621826172, ablated_edges=1127\n",
      "loss.item()=-45.18414306640625, ablated_edges=1077\n",
      "loss.item()=-44.099369049072266, ablated_edges=1033\n",
      "loss.item()=-46.79762268066406, ablated_edges=1014\n",
      "loss.item()=-46.98273849487305, ablated_edges=985\n",
      "loss.item()=-47.27374267578125, ablated_edges=981\n",
      "loss.item()=-48.92109298706055, ablated_edges=905\n",
      "Epochs trained:  50\n",
      "Loss: -48.9211\n",
      "Total preserved: 10555.3887\n",
      "Edges ablated:  908\n",
      "Toxic loss:  112.21772766113281\n",
      "OWT loss:  4.133076190948486\n",
      "Penalty:  tensor(30.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "loss.item()=-50.16511535644531, ablated_edges=943\n",
      "loss.item()=-52.14141082763672, ablated_edges=887\n",
      "loss.item()=-53.84297180175781, ablated_edges=907\n",
      "loss.item()=-55.491737365722656, ablated_edges=854\n",
      "loss.item()=-52.80794906616211, ablated_edges=926\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     penalty \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, p\u001b[39m.\u001b[39msum() \u001b[39m*\u001b[39m (epochs_trained\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m10000\u001b[39m) \u001b[39m# why 2000? free\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# demos = batch[:, :FILTER_DEMO_LEN]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# completions = batch[:, FILTER_DEMO_LEN:]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# tox_loss = infer_batch(model, criterion, completions, toxic_batch_size, demos)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# owt_loss = infer_batch(model, criterion, next(owt_iter)['tokens'], owt_batch_size, fixed_demos)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m tox_loss, owt_loss \u001b[39m=\u001b[39m infer_batch_with_owt(model, criterion, batch, \u001b[39mnext\u001b[39;49m(owt_iter), batch_size, demos, access_toxic_pos\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# print(f\"{tox_loss=}, {owt_loss=}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/analyze_ioi_mask.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m (penalty \u001b[39m+\u001b[39m alpha \u001b[39m*\u001b[39m tox_loss) \u001b[39m+\u001b[39m owt_loss\n",
      "File \u001b[0;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/inference.py:80\u001b[0m, in \u001b[0;36minfer_batch_with_owt\u001b[0;34m(model, criterion, toxic_batch, owt_batch, batch_size, demos, device, access_toxic_pos)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m batch\n\u001b[1;32m     77\u001b[0m \u001b[39m# print(input.shape, input.dtype)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[39m# generate the output\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m out \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m)[\u001b[39m0\u001b[39m]  \u001b[39m# 0 is the logits\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39m# print(f\"{out.shape=}, {demos.shape=}\")\u001b[39;00m\n\u001b[1;32m     84\u001b[0m losses[idx] \u001b[39m=\u001b[39m evaluate_sequence_loss(out, \u001b[39minput\u001b[39m, criterion, demos\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], access_seq_pos\u001b[39m=\u001b[39maccess_toxic_pos \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/transformer.py:266\u001b[0m, in \u001b[0;36mDemoTransformer.forward\u001b[0;34m(self, tokens, return_states)\u001b[0m\n\u001b[1;32m    262\u001b[0m residual \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(residual, \u001b[39m\"\u001b[39m\u001b[39mbatch position d_model -> batch position 1 d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    264\u001b[0m \u001b[39mfor\u001b[39;00m i, block \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks):\n\u001b[1;32m    265\u001b[0m     \u001b[39m# print(i)\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     residual \u001b[39m=\u001b[39m block(residual, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeans)\n\u001b[1;32m    267\u001b[0m     \u001b[39m# if hasattr(self,\"saved_states\"):\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39m#     self.saved_states = torch.cat((self.saved_states, block.saved_output.unsqueeze(0)), dim=0)\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[39m# else:\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \u001b[39m#     self.saved_states = block.saved_output.unsqueeze(0)\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m return_states:\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/transformer.py:216\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, means)\u001b[0m\n\u001b[1;32m    213\u001b[0m masked_mlp_residual \u001b[39m=\u001b[39m einsum(\u001b[39m\"\u001b[39m\u001b[39mbatch position prev_head_idx d_model, prev_head_idx -> batch position d_model\u001b[39m\u001b[39m\"\u001b[39m, residual, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_mask_mlp)\n\u001b[1;32m    215\u001b[0m normalized_resid_mid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln2(masked_mlp_residual)\n\u001b[0;32m--> 216\u001b[0m mlp_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(normalized_resid_mid)\n\u001b[1;32m    217\u001b[0m mlp_out \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(mlp_out, \u001b[39m\"\u001b[39m\u001b[39mbatch position d_model -> batch position 1 d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m residual \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((residual, mlp_out), dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/phil/deep_learning/mechanistic-unlearning/circuit-breaking/ioi/transformer.py:167\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, normalized_resid_mid)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mdebug: \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNormalized_resid_mid:\u001b[39m\u001b[39m\"\u001b[39m, normalized_resid_mid\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    166\u001b[0m pre \u001b[39m=\u001b[39m einsum(\u001b[39m\"\u001b[39m\u001b[39mbatch position d_model, d_model d_mlp -> batch position d_mlp\u001b[39m\u001b[39m\"\u001b[39m, normalized_resid_mid, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_in) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_in\n\u001b[0;32m--> 167\u001b[0m post \u001b[39m=\u001b[39m gelu_new(pre)\n\u001b[1;32m    168\u001b[0m mlp_out \u001b[39m=\u001b[39m einsum(\u001b[39m\"\u001b[39m\u001b[39mbatch position d_mlp, d_mlp d_model -> batch position d_model\u001b[39m\u001b[39m\"\u001b[39m, post, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_out) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_out\n\u001b[1;32m    169\u001b[0m \u001b[39mreturn\u001b[39;00m mlp_out\n",
      "File \u001b[0;32m/home/phil/.conda/envs/unlrn/lib/python3.10/site-packages/easy_transformer/utils.py:97\u001b[0m, in \u001b[0;36mgelu_new\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m         \u001b[39mreturn\u001b[39;00m correct_matches\u001b[39m.\u001b[39msum()\u001b[39m/\u001b[39mcorrect_matches\u001b[39m.\u001b[39mnumel()\n\u001b[0;32m---> 97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgelu_new\u001b[39m(\u001b[39minput\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[39m# Implementation of GeLU used by GPT2 - subtly different from PyTorch's\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    100\u001b[0m         \u001b[39m0.5\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[39m*\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgelu_fast\u001b[39m(\u001b[39minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prev_params = None\n",
    "while epochs_left > 0:\n",
    "    for e in tqdm(range(epochs_left)):\n",
    "        for c, batch in enumerate(toxic_data_loader):\n",
    "            if c > max_steps_per_epoch:\n",
    "                break\n",
    "\n",
    "            # print(batch[\"text\"])\n",
    "            total_preserving = 0\n",
    "            ablated_edges = 0\n",
    "            penalty = 0\n",
    "            for p in mask_params:\n",
    "                total_preserving += p.sum()\n",
    "                ablated_edges += p[p.data < 0.5].shape[0]\n",
    "                penalty += max(0, p.sum() * (epochs_trained-20) / 10000) # why 2000? free\n",
    "\n",
    "            # demos = batch[:, :FILTER_DEMO_LEN]\n",
    "            # completions = batch[:, FILTER_DEMO_LEN:]\n",
    "\n",
    "            # tox_loss = infer_batch(model, criterion, completions, toxic_batch_size, demos)\n",
    "            # owt_loss = infer_batch(model, criterion, next(owt_iter)['tokens'], owt_batch_size, fixed_demos)\n",
    "            tox_loss, owt_loss = infer_batch_with_owt(model, criterion, batch, next(owt_iter), batch_size, demos, access_toxic_pos=-1)\n",
    "            # print(f\"{tox_loss=}, {owt_loss=}\")\n",
    "            loss = -1 * (penalty + alpha * tox_loss) + owt_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(loss.item())\n",
    "            num_ablated_edges.append(ablated_edges)\n",
    "            for p in mask_params:\n",
    "                p.data.clamp_(0,1)\n",
    "        print(f\"{loss.item()=}, {ablated_edges=}\")\n",
    "        epochs_trained += 1\n",
    "        if epochs_trained % clamp_every == 0:\n",
    "            ablated_edges = 0\n",
    "            for p in mask_params:\n",
    "                p.data[p.data < threshold] = 0\n",
    "                p.data[p.data >= threshold] = 1\n",
    "                ablated_edges += p[p.data < 0.5].shape[0]\n",
    "        if epochs_trained % log_every == 0:\n",
    "            print(\"Epochs trained: \", epochs_trained)\n",
    "            print(f\"Loss: {loss.item():.4f}\")\n",
    "            print(f\"Total preserved: {total_preserving:.4f}\")\n",
    "            print(\"Edges ablated: \", ablated_edges)\n",
    "            print(\"Toxic loss: \", tox_loss.item())\n",
    "            print(\"OWT loss: \", owt_loss.item())\n",
    "            print(\"Penalty: \", penalty)\n",
    "            # if input('evaluate? (y)') == 'y':\n",
    "            #     evaluate_model(model, toxic_batches=1, owt_batches=1)\n",
    "            print(\"\\n\")\n",
    "                \n",
    "        if epochs_trained > 50 and ablated_edges < edge_threshold:\n",
    "            break\n",
    "        prev_params = mask_params\n",
    "    epochs_left = int(input('continue training for this number of epochs: '))\n",
    "    log_every = int(input('set log frequency'))\n",
    "    edge_threshold = int(input('set edge threshold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10630., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "total_preserving = 0\n",
    "for p in mask_params:\n",
    "    p.data[p.data < threshold] = 0\n",
    "    p.data[p.data >= threshold] = 1\n",
    "    total_preserving += p.data.sum()\n",
    "print(total_preserving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 0.], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1.], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [0., 1., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 0.], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 1., 0.]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 1., 1.], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 0., 1., 1.]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0.], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, x in model.named_parameters():\n",
    "    if x.requires_grad:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_mask: torch.Size([157])\n",
      "blocks.0.edge_mask_attentions: torch.Size([1, 12])\n",
      "blocks.0.edge_mask_mlp: torch.Size([13])\n",
      "blocks.1.edge_mask_attentions: torch.Size([14, 12])\n",
      "blocks.1.edge_mask_mlp: torch.Size([26])\n",
      "blocks.2.edge_mask_attentions: torch.Size([27, 12])\n",
      "blocks.2.edge_mask_mlp: torch.Size([39])\n",
      "blocks.3.edge_mask_attentions: torch.Size([40, 12])\n",
      "blocks.3.edge_mask_mlp: torch.Size([52])\n",
      "blocks.4.edge_mask_attentions: torch.Size([53, 12])\n",
      "blocks.4.edge_mask_mlp: torch.Size([65])\n",
      "blocks.5.edge_mask_attentions: torch.Size([66, 12])\n",
      "blocks.5.edge_mask_mlp: torch.Size([78])\n",
      "blocks.6.edge_mask_attentions: torch.Size([79, 12])\n",
      "blocks.6.edge_mask_mlp: torch.Size([91])\n",
      "blocks.7.edge_mask_attentions: torch.Size([92, 12])\n",
      "blocks.7.edge_mask_mlp: torch.Size([104])\n",
      "blocks.8.edge_mask_attentions: torch.Size([105, 12])\n",
      "blocks.8.edge_mask_mlp: torch.Size([117])\n",
      "blocks.9.edge_mask_attentions: torch.Size([118, 12])\n",
      "blocks.9.edge_mask_mlp: torch.Size([130])\n",
      "blocks.10.edge_mask_attentions: torch.Size([131, 12])\n",
      "blocks.10.edge_mask_mlp: torch.Size([143])\n",
      "blocks.11.edge_mask_attentions: torch.Size([144, 12])\n",
      "blocks.11.edge_mask_mlp: torch.Size([156])\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(mask_params)):\n",
    "    print(f\"{param_names[idx]}: {mask_params[idx].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model before and after circuit breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/ioi_sentences_test.pkl\", \"rb\") as f:\n",
    "    ioi_sentences_test = pickle.load(f)\n",
    "    # ioi_sentences_test = [t[2] for t in ioi_sentences_test]\n",
    "\n",
    "with open(\"data/eval_uniform.pkl\", \"rb\") as f:\n",
    "    uniform_samples = pickle.load(f)\n",
    "    uniform_sentences = [t[2] for t in uniform_samples]\n",
    "\n",
    "original_model = load_demo_gpt2(means=False)\n",
    "\n",
    "with open(\"models/masked_gpt2_mean_ablation_v6.pkl\", \"rb\") as f:\n",
    "    model.state_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then, John and Ryan had a lot of fun at the office. John gave a snack to Ryan\n",
      "Before ablation\n",
      " Ryan, probability of 0.3558429777622223\n",
      " his, probability of 0.11594294011592865\n",
      " the, probability of 0.08989984542131424\n",
      " John, probability of 0.031978804618120193\n",
      " a, probability of 0.023939691483974457\n",
      "\n",
      "\n",
      "After ablation\n",
      " use, probability of 0.999350368976593\n",
      " share, probability of 8.960117702372372e-05\n",
      " take, probability of 8.413783507421613e-05\n",
      " try, probability of 7.346251368289813e-05\n",
      " apply, probability of 4.8839792725630105e-05\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an ioi_sentence\n",
    "ioi_sentence = ioi_sentences_test[0]\n",
    "print(ioi_sentence)\n",
    "# ioi_tokens = tokenizer(ioi_sentence, return_tensors='pt').input_ids.to('cuda')\n",
    "\n",
    "original_model.eval()\n",
    "original_model.to('cuda')\n",
    "def get_last_token(model, prompt, topk=5):\n",
    "    # generate last token\n",
    "    tokens = tokenizer(prompt, return_tensors='pt').input_ids[:, :-1]\n",
    "\n",
    "    # generate one token, decode original_model(ioi_tokens[:, :-1])\n",
    "    model_outputs = model(tokens)[0]\n",
    "    model_outputs = model_outputs.squeeze(0)[-1]\n",
    "    probs = torch.nn.functional.softmax(model_outputs, dim=-1)\n",
    "\n",
    "    topk_outputs = torch.topk(model_outputs, topk)\n",
    "    topk_tokens = topk_outputs.indices\n",
    "    topk_probs = probs[topk_outputs.indices]\n",
    "    \n",
    "    # decode tokens\n",
    "    for i in range(topk):\n",
    "        print(f\"{tokenizer.decode(topk_tokens[i].unsqueeze(0))}, probability of {topk_probs[i]}\")\n",
    "    topk_tokens_decoded = tokenizer.batch_decode(topk_tokens)\n",
    "    return topk_tokens_decoded, topk_probs\n",
    "\n",
    "print(\"Before ablation\")\n",
    "_ = get_last_token(original_model, ioi_sentence)\n",
    "print()\n",
    "print()\n",
    "print(\"After ablation\")\n",
    "_ = get_last_token(model, ioi_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREEN AND PURPLE RAIN\n",
      "Before ablation\n",
      "IN, probability of 0.5235788822174072\n",
      "IS, probability of 0.1651604324579239\n",
      "IL, probability of 0.06369347870349884\n",
      "INS, probability of 0.04333753511309624\n",
      "Z, probability of 0.03196313977241516\n",
      "\n",
      "After ablation\n",
      "FF, probability of 0.16773802042007446\n",
      "KE, probability of 0.15770037472248077\n",
      "VE, probability of 0.15650776028633118\n",
      "VEN, probability of 0.09344792366027832\n",
      "IN, probability of 0.06106434762477875\n",
      "\n",
      "\n",
      "\n",
      "ROBOT! ROBOT ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT! ROBOT!\n",
      "Before ablation\n",
      "!, probability of 0.9894324541091919\n",
      "., probability of 0.007035684306174517\n",
      ":, probability of 0.0009531358373351395\n",
      "!!, probability of 0.0004606391885317862\n",
      "\n",
      ", probability of 0.00021542994363699108\n",
      "\n",
      "After ablation\n",
      "ANGE, probability of 0.10324295610189438\n",
      ":, probability of 0.07972729951143265\n",
      "AL, probability of 0.07847077399492264\n",
      "IF, probability of 0.059709884226322174\n",
      "AN, probability of 0.05356771498918533\n",
      "\n",
      "\n",
      "\n",
      "bennigansOn February 11, 2015, CEO Paul Mangiamele and his wife, Gwen, closed on a Management Buy Out (MBO) of the company from its parent private equity firm, for an undisclosed price. The new company, Legendary Restaurant Brands, LLC, is now the owner of the Bennigans restaurant chain, its fast-casual concept Bennigans On the Fly, and the Steak and Ale brand.[12]Currently, Bennigans operates 23 domestic and 39 international locations in eight other countries.\n",
      "Before ablation\n",
      "., probability of 0.37817808985710144\n",
      ",, probability of 0.2304694503545761\n",
      " and, probability of 0.06781601160764694\n",
      ".[, probability of 0.04922689124941826\n",
      " around, probability of 0.03863804042339325\n",
      "\n",
      "After ablation\n",
      "., probability of 0.4005994498729706\n",
      ":, probability of 0.2261192798614502\n",
      ",, probability of 0.06644211709499359\n",
      " such, probability of 0.02817697264254093\n",
      " like, probability of 0.01595304347574711\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try on uniform samples\n",
    "for idx in range(3):\n",
    "    print(uniform_sentences[idx])\n",
    "    print(\"Before ablation\")\n",
    "    _ = get_last_token(original_model, uniform_sentences[idx])\n",
    "    print()\n",
    "    print(\"After ablation\")\n",
    "    _ = get_last_token(model, uniform_sentences[idx])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize mask\n",
    "Code from ChatGPT lol, meant to look like the computational graphs in edge attribution patching paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygraphviz as pgv\n",
    "\n",
    "# Let's assume you have a list of masks with ones or zeros\n",
    "# Each element of `masks` is a tuple containing the mask for attentions and mlp for each block\n",
    "# For simplicity, the masks are randomly generated\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_blocks = 12\n",
    "num_heads = 12\n",
    "num_mlp_units = 13\n",
    "\n",
    "# Generating random masks\n",
    "masks = [\n",
    "    (np.random.randint(2, size=(num_heads,)), np.random.randint(2, size=(num_mlp_units,)))\n",
    "    for _ in range(num_blocks)\n",
    "]\n",
    "\n",
    "# Create a new directed graph\n",
    "G = pgv.AGraph(directed=True)\n",
    "\n",
    "# Add the embed node\n",
    "G.add_node(\"embed\", color=\"blue\")\n",
    "\n",
    "# Add nodes and edges for each block\n",
    "for i in range(num_blocks):\n",
    "    attention_mask, mlp_mask = masks[i]\n",
    "\n",
    "    # Add attention nodes\n",
    "    for j in range(num_heads):\n",
    "        node_name = f\"block_{i}_head_{j}\"\n",
    "        G.add_node(node_name, color=\"blue\")\n",
    "        if i == 0:  # Connect the first block's attention directly to embed\n",
    "            G.add_edge(\"embed\", node_name)\n",
    "        else:  # Connect to previous blocks based on the mask\n",
    "            for k in range(num_heads):\n",
    "                if attention_mask[j] == 0:\n",
    "                    G.add_edge(f\"block_{i-1}_head_{k}\", node_name)\n",
    "\n",
    "    # Add MLP node\n",
    "    mlp_node_name = f\"block_{i}_mlp\"\n",
    "    G.add_node(mlp_node_name, color=\"blue\")\n",
    "\n",
    "    # Connect MLP to all previous heads based on the mask\n",
    "    for j in range(num_heads):\n",
    "        for k in range(i+1):  # +1 because it connects to its own block as well\n",
    "            if mlp_mask[j] == 0:\n",
    "                G.add_edge(f\"block_{k}_head_{j}\", mlp_node_name)\n",
    "\n",
    "# Add the resid_post node and connect the last block's mlp to it\n",
    "G.add_node(\"resid_post\", color=\"blue\")\n",
    "G.add_edge(f\"block_{num_blocks-1}_mlp\", \"resid_post\")\n",
    "\n",
    "# Render the graph to a file (you can specify different file formats)\n",
    "G.draw('graph.png', prog='dot')  # Use 'dot' for hierarchical layouts similar to your example\n",
    "\n",
    "print(\"Graph created and saved as 'graph.png'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlrn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
